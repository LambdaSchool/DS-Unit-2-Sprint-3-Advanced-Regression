{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_233_Quantile_Regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnpharmd/DS-Unit-2-Sprint-3-Advanced-Regression/blob/master/module3-quantile-regression/LS_DS_233_Quantile_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SV7gaADiicnV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lambda School Data Science - Quantile Regression\n",
        "\n",
        "Regressing towards the median - or any quantile - as a way to mitigate outliers and control risk."
      ]
    },
    {
      "metadata": {
        "id": "6klMj4q3iqMh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lecture\n",
        "\n",
        "Let's look at data that has a bit of a skew to it:\n",
        "\n",
        "http://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data"
      ]
    },
    {
      "metadata": {
        "id": "yw1AD_z9O0xL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
        "                 '00381/PRSA_data_2010.1.1-2014.12.31.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RTlH1lJ8PDv5",
        "colab_type": "code",
        "outputId": "3c7c56b5-b2b6-4703-d5ef-2b97231c0b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "df.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43824, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "m-yC9OSPPFo8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hfV3WisFP_O6",
        "colab_type": "code",
        "outputId": "9a38d106-dd8b-4da5-991d-421fcb933062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "df['pm2.5'].plot.hist();"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFKCAYAAAAXA4ZFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "J2zc3U1-n65G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2694a8d6-3c5a-4550-b343-812584ae9ea4"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "df1 = df.copy()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "OgbMTAHzQJB8",
        "colab_type": "code",
        "outputId": "510a0d34-39cd-4268-d3b0-d58182030240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "# How does linear regression handle it?\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Let's drop NAs and limit to numeric values\n",
        "df = df._get_numeric_data().dropna()\n",
        "X = df.drop('pm2.5', axis='columns')\n",
        "y = df['pm2.5']\n",
        "\n",
        "linear_reg = LinearRegression().fit(X, y)\n",
        "linear_reg.score(X, y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2590006399659215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "-viFFtm0RizM",
        "colab_type": "code",
        "outputId": "c9fe8f90-0f0c-4b4e-8896-546afb1de333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "cell_type": "code",
      "source": [
        "# Not bad - but what if we wanted to model the distribution more conservatively?\n",
        "# Let's try quantile\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# Different jargon/API in StatsModel documentation\n",
        "# \"endogenous\" response var is dependent (y), it is \"inside\"\n",
        "# \"exogenous\" variables are independent (X), it is \"outside\"\n",
        "# Bonus points - talk about \"exogenous shocks\" and you're a bona fide economist\n",
        "\n",
        "# ~ style formulas look like what R uses\n",
        "# y ~ x1 + x2 + ...\n",
        "\n",
        "# NOTE: per AG from lecture, think of y ~... as \"y is modeled as...\" -- from about 27minutes into lecture video\n",
        "\n",
        "# Also, these formulas break with . in variable name, so lets change that\n",
        "df = df.rename(index=str, columns={'pm2.5': 'pm25'})\n",
        "\n",
        "# Now let's construct the formula string using all columns\n",
        "quant_formula = 'pm25 ~ ' + ' + '.join(df.drop('pm25', axis='columns').columns)\n",
        "print(quant_formula)\n",
        "\n",
        "quant_mod = smf.quantreg(quant_formula, data=df)\n",
        "quant_reg = quant_mod.fit(q=.5)\n",
        "quant_reg.summary()  # \"summary\" is another very R-thing"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pm25 ~ No + year + month + day + hour + DEWP + TEMP + PRES + Iws + Is + Ir\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>QuantReg Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>       <td>pm25</td>       <th>  Pseudo R-squared:  </th> <td>  0.1600</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>             <td>QuantReg</td>     <th>  Bandwidth:         </th> <td>   8.276</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>          <td>Least Squares</td>  <th>  Sparsity:          </th> <td>   133.8</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>          <td>Wed, 30 Jan 2019</td> <th>  No. Observations:  </th>  <td> 41757</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>              <td>21:07:54</td>     <th>  Df Residuals:      </th>  <td> 41745</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th> </th>                      <td> </td>        <th>  Df Model:          </th>  <td>    11</td> \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>    0.0004</td> <td> 1.67e-05</td> <td>   22.881</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No</th>        <td>  3.63e-07</td> <td> 2.67e-05</td> <td>    0.014</td> <td> 0.989</td> <td> -5.2e-05</td> <td> 5.27e-05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>year</th>      <td>    0.8830</td> <td>    0.031</td> <td>   28.631</td> <td> 0.000</td> <td>    0.823</td> <td>    0.943</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>month</th>     <td>   -1.4110</td> <td>    0.103</td> <td>  -13.749</td> <td> 0.000</td> <td>   -1.612</td> <td>   -1.210</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>day</th>       <td>    0.4461</td> <td>    0.037</td> <td>   11.951</td> <td> 0.000</td> <td>    0.373</td> <td>    0.519</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>hour</th>      <td>    1.2810</td> <td>    0.050</td> <td>   25.779</td> <td> 0.000</td> <td>    1.184</td> <td>    1.378</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>DEWP</th>      <td>    3.6362</td> <td>    0.047</td> <td>   77.315</td> <td> 0.000</td> <td>    3.544</td> <td>    3.728</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>TEMP</th>      <td>   -4.7103</td> <td>    0.060</td> <td>  -78.779</td> <td> 0.000</td> <td>   -4.828</td> <td>   -4.593</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>PRES</th>      <td>   -1.6265</td> <td>    0.061</td> <td>  -26.760</td> <td> 0.000</td> <td>   -1.746</td> <td>   -1.507</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Iws</th>       <td>   -0.1541</td> <td>    0.007</td> <td>  -21.786</td> <td> 0.000</td> <td>   -0.168</td> <td>   -0.140</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Is</th>        <td>   -1.6322</td> <td>    0.425</td> <td>   -3.838</td> <td> 0.000</td> <td>   -2.466</td> <td>   -0.799</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Ir</th>        <td>   -5.3946</td> <td>    0.234</td> <td>  -23.034</td> <td> 0.000</td> <td>   -5.854</td> <td>   -4.936</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                         QuantReg Regression Results                          \n",
              "==============================================================================\n",
              "Dep. Variable:                   pm25   Pseudo R-squared:               0.1600\n",
              "Model:                       QuantReg   Bandwidth:                       8.276\n",
              "Method:                 Least Squares   Sparsity:                        133.8\n",
              "Date:                Wed, 30 Jan 2019   No. Observations:                41757\n",
              "Time:                        21:07:54   Df Residuals:                    41745\n",
              "                                        Df Model:                           11\n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept      0.0004   1.67e-05     22.881      0.000       0.000       0.000\n",
              "No           3.63e-07   2.67e-05      0.014      0.989    -5.2e-05    5.27e-05\n",
              "year           0.8830      0.031     28.631      0.000       0.823       0.943\n",
              "month         -1.4110      0.103    -13.749      0.000      -1.612      -1.210\n",
              "day            0.4461      0.037     11.951      0.000       0.373       0.519\n",
              "hour           1.2810      0.050     25.779      0.000       1.184       1.378\n",
              "DEWP           3.6362      0.047     77.315      0.000       3.544       3.728\n",
              "TEMP          -4.7103      0.060    -78.779      0.000      -4.828      -4.593\n",
              "PRES          -1.6265      0.061    -26.760      0.000      -1.746      -1.507\n",
              "Iws           -0.1541      0.007    -21.786      0.000      -0.168      -0.140\n",
              "Is            -1.6322      0.425     -3.838      0.000      -2.466      -0.799\n",
              "Ir            -5.3946      0.234    -23.034      0.000      -5.854      -4.936\n",
              "==============================================================================\n",
              "\n",
              "The condition number is large, 3.67e+10. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "Dzen1Jjru6UI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[Wikipedia on Quantile Regression](https://en.wikipedia.org/wiki/Quantile_regression)  \n",
        "AG addresses gradient descent approach to solving linear regression [about 29:00 in to lecture video]...  \n",
        "AG: \"We're minimizing some cost, some error.\"  Key term: loss function"
      ]
    },
    {
      "metadata": {
        "id": "ZBkP4bewd-HT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "That fit to the median (q=0.5), also called \"Least Absolute Deviation.\" NOTE: this is a special case of quantile regression [about 30:30 in to lecture].  \n",
        "\"This is not BLUE\", states AG. Key: this is minimizing the sum of error, per AG. Utility of QR over LinReg, per AG, is ability to fine tune parameters.  \n",
        "The pseudo-R^2 isn't really directly comparable to the R^2 from linear regression, but it clearly isn't dramatically improved. Can we make it better?"
      ]
    },
    {
      "metadata": {
        "id": "BgvYeHg3bL4g",
        "colab_type": "code",
        "outputId": "0f6672f5-690e-4a05-edbb-b6b1678c272c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "cell_type": "code",
      "source": [
        "help(quant_mod.fit)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on method fit in module statsmodels.regression.quantile_regression:\n",
            "\n",
            "fit(q=0.5, vcov='robust', kernel='epa', bandwidth='hsheather', max_iter=1000, p_tol=1e-06, **kwargs) method of statsmodels.regression.quantile_regression.QuantReg instance\n",
            "    Solve by Iterative Weighted Least Squares\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    q : float\n",
            "        Quantile must be between 0 and 1\n",
            "    vcov : string, method used to calculate the variance-covariance matrix\n",
            "        of the parameters. Default is ``robust``:\n",
            "    \n",
            "        - robust : heteroskedasticity robust standard errors (as suggested\n",
            "          in Greene 6th edition)\n",
            "        - iid : iid errors (as in Stata 12)\n",
            "    \n",
            "    kernel : string, kernel to use in the kernel density estimation for the\n",
            "        asymptotic covariance matrix:\n",
            "    \n",
            "        - epa: Epanechnikov\n",
            "        - cos: Cosine\n",
            "        - gau: Gaussian\n",
            "        - par: Parzene\n",
            "    \n",
            "    bandwidth: string, Bandwidth selection method in kernel density\n",
            "        estimation for asymptotic covariance estimate (full\n",
            "        references in QuantReg docstring):\n",
            "    \n",
            "        - hsheather: Hall-Sheather (1988)\n",
            "        - bofinger: Bofinger (1975)\n",
            "        - chamberlain: Chamberlain (1994)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lpNPioZTei4U",
        "colab_type": "code",
        "outputId": "5c26cac3-2892-4d79-ab44-4a7d997f5805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1532
        }
      },
      "cell_type": "code",
      "source": [
        "quantiles = (.05, .96, .1)\n",
        "\n",
        "for quantile in quantiles:\n",
        "  print(quant_mod.fit(q=quantile).summary())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                         QuantReg Regression Results                          \n",
            "==============================================================================\n",
            "Dep. Variable:                   pm25   Pseudo R-squared:              0.04130\n",
            "Model:                       QuantReg   Bandwidth:                       8.908\n",
            "Method:                 Least Squares   Sparsity:                        120.7\n",
            "Date:                Wed, 30 Jan 2019   No. Observations:                41757\n",
            "Time:                        21:12:48   Df Residuals:                    41745\n",
            "                                        Df Model:                           11\n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept   3.072e-05    6.4e-06      4.803      0.000    1.82e-05    4.33e-05\n",
            "No         -6.994e-05   9.59e-06     -7.292      0.000   -8.87e-05   -5.11e-05\n",
            "year           0.0998      0.012      8.275      0.000       0.076       0.123\n",
            "month         -0.4536      0.034    -13.419      0.000      -0.520      -0.387\n",
            "day            0.1143      0.015      7.862      0.000       0.086       0.143\n",
            "hour           0.3777      0.020     19.013      0.000       0.339       0.417\n",
            "DEWP           0.7720      0.014     55.266      0.000       0.745       0.799\n",
            "TEMP          -0.8346      0.020    -41.621      0.000      -0.874      -0.795\n",
            "PRES          -0.1734      0.024     -7.290      0.000      -0.220      -0.127\n",
            "Iws           -0.0364      0.002    -17.462      0.000      -0.040      -0.032\n",
            "Is             1.4573      0.195      7.466      0.000       1.075       1.840\n",
            "Ir            -1.2952      0.071    -18.209      0.000      -1.435      -1.156\n",
            "==============================================================================\n",
            "\n",
            "The condition number is large, 3.67e+10. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "                         QuantReg Regression Results                          \n",
            "==============================================================================\n",
            "Dep. Variable:                   pm25   Pseudo R-squared:               0.2194\n",
            "Model:                       QuantReg   Bandwidth:                       10.41\n",
            "Method:                 Least Squares   Sparsity:                        1322.\n",
            "Date:                Wed, 30 Jan 2019   No. Observations:                41757\n",
            "Time:                        21:12:49   Df Residuals:                    41745\n",
            "                                        Df Model:                           11\n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept      0.0004   6.87e-05      5.306      0.000       0.000       0.000\n",
            "No          7.821e-05      0.000      0.696      0.486      -0.000       0.000\n",
            "year           1.0580      0.124      8.539      0.000       0.815       1.301\n",
            "month         -3.9661      0.446     -8.895      0.000      -4.840      -3.092\n",
            "day            1.0816      0.136      7.936      0.000       0.814       1.349\n",
            "hour           2.3661      0.192     12.354      0.000       1.991       2.741\n",
            "DEWP           7.5176      0.235     32.004      0.000       7.057       7.978\n",
            "TEMP         -11.6991      0.302    -38.691      0.000     -12.292     -11.106\n",
            "PRES          -1.7121      0.244     -7.003      0.000      -2.191      -1.233\n",
            "Iws           -0.4151      0.034    -12.339      0.000      -0.481      -0.349\n",
            "Is            -5.7267      1.580     -3.624      0.000      -8.824      -2.630\n",
            "Ir            -9.3197      1.457     -6.397      0.000     -12.175      -6.464\n",
            "==============================================================================\n",
            "\n",
            "The condition number is large, 3.67e+10. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "                         QuantReg Regression Results                          \n",
            "==============================================================================\n",
            "Dep. Variable:                   pm25   Pseudo R-squared:              0.06497\n",
            "Model:                       QuantReg   Bandwidth:                       8.092\n",
            "Method:                 Least Squares   Sparsity:                        104.4\n",
            "Date:                Wed, 30 Jan 2019   No. Observations:                41757\n",
            "Time:                        21:12:51   Df Residuals:                    41745\n",
            "                                        Df Model:                           11\n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept   5.214e-05   7.84e-06      6.650      0.000    3.68e-05    6.75e-05\n",
            "No         -9.232e-05   1.17e-05     -7.888      0.000      -0.000   -6.94e-05\n",
            "year           0.1521      0.015     10.386      0.000       0.123       0.181\n",
            "month         -0.5581      0.042    -13.138      0.000      -0.641      -0.475\n",
            "day            0.1708      0.017      9.893      0.000       0.137       0.205\n",
            "hour           0.4604      0.024     19.350      0.000       0.414       0.507\n",
            "DEWP           1.2350      0.017     70.845      0.000       1.201       1.269\n",
            "TEMP          -1.3088      0.024    -54.101      0.000      -1.356      -1.261\n",
            "PRES          -0.2652      0.029     -9.183      0.000      -0.322      -0.209\n",
            "Iws           -0.0436      0.003    -16.919      0.000      -0.049      -0.039\n",
            "Is             1.0745      0.231      4.653      0.000       0.622       1.527\n",
            "Ir            -1.9619      0.087    -22.504      0.000      -2.133      -1.791\n",
            "==============================================================================\n",
            "\n",
            "The condition number is large, 3.67e+10. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nb8nb73V0Ag9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pretend R code [recapitulating AG's demonstration]  \n",
        "```\n",
        "ols1 <- lm(y ~ x1 + x2 + (x1 * x1))  \n",
        "summary(ols1)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "Xqh4Jp1XgjrE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\"Strong multicollinearity\", eh? In other words - maybe we shouldn't throw every variable in our formula. Let's hand-craft a smaller one, picking the features with the largest magnitude t-statistics for their coefficients. Let's also search for more quantile cutoffs to see what's most effective.  \n",
        "\n",
        "**Key** [at about 34:00]: Per AG, don't necessarily want to optimize for Pseudo-R^2. As this metric increases, however, model generally is more successful at \"explaining the cutoffs above and below the associated quantile\".  \n",
        "\n",
        "Good reference, courtesy of AG: https://data.library.virginia.edu/getting-started-with-quantile-regression/  \n",
        "\n",
        "**Key** [at about 42:45]: AG discusses robustness versus regularization. \"Mitigating outliers is robustness. This is different from regularization, which has to do  \n",
        "with overfitting. Both robustness and regularization are optimization approaches with models.\"  AG also discusses example of Shopify's use of QR to determine  \n",
        "how it loans capital to merchants."
      ]
    },
    {
      "metadata": {
        "id": "NmoELnXwgpXd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "quant_formula = 'pm25 ~ DEWP + TEMP + Ir + hour + Iws'\n",
        "quant_mod = smf.quantreg(quant_formula, data=df)\n",
        "for quantile in range(50, 100):\n",
        "  quantile /= 100\n",
        "  quant_reg = quant_mod.fit(q=quantile)\n",
        "  print((quantile, quant_reg.prsquared))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bz0GmE5kuwQY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Okay, this data seems *extremely* skewed\n",
        "# Let's trying logging\n",
        "import numpy as np\n",
        "\n",
        "df['pm25'] = np.log(1 + df['pm25'])\n",
        "quant_mod = smf.quantreg(quant_formula, data=df)\n",
        "quant_reg = quant_mod.fit(q=.25)\n",
        "quant_reg.summary()  # \"summary\" is another very R-thing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8kXcxnNBgizX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Overall - in this case, quantile regression is not *necessarily* superior to linear regression. But it does give us extra flexibility and another thing to tune - what the center of what we're actually fitting in the dependent variable.\n",
        "\n",
        "The basic case of `q=0.5` (the median) minimizes the absolute value of residuals, while OLS minimizes the squared value. By selecting `q=0.25`, we're targeting a lower quantile and are effectively saying that we only want to over-estimate at most 25% of the time - we're being *risk averse*.\n",
        "\n",
        "Depending on the data you're looking at, and the cost of making a false positive versus a false negative, this sort of flexibility can be extremely useful.\n",
        "\n",
        "Live - let's consider another dataset! Specifically, \"SkillCraft\" (data on competitive StarCraft players): http://archive.ics.uci.edu/ml/datasets/SkillCraft1+Master+Table+Dataset"
      ]
    },
    {
      "metadata": {
        "id": "ofvwSAZUhWDw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO Live!\n",
        "# Hint - we may only care about the *top* quantiles here\n",
        "# Another hint - there are missing values, but Pandas won't see them right away"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o2BADEQUirXa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assignment - birth weight data\n",
        "\n",
        "Birth weight is a situation where, while the data itself is actually fairly normal and symmetric, our main goal is actually *not* to model mean weight (via OLS), but rather to identify mothers at risk of having children below a certain \"at-risk\" threshold weight.\n",
        "\n",
        "Quantile regression gives us just the tool we need. For the data we are using, see: http://people.reed.edu/~jones/141/BirthWgt.html\n",
        "\n",
        "    bwt: baby's weight in ounces at birth\n",
        "    gestation: duration of pregnancy in days\n",
        "    parity: parity indicator (first born = 1, later birth = 0)\n",
        "    age: mother's age in years\n",
        "    height: mother's height in inches\n",
        "    weight: mother's weight in pounds (during pregnancy)\n",
        "    smoke: indicator for whether mother smokes (1=yes, 0=no) \n",
        "    \n",
        "Use this data and `statsmodels` to fit a quantile regression, predicting `bwt` (birth weight) as a function of the other covariates. First, identify an appropriate `q` (quantile) to target a cutoff of 90 ounces - babies above that birth weight are generally healthy/safe, babies below are at-risk.\n",
        "\n",
        "Then, fit and iterate your model. Be creative! You may want to engineer features. Hint - mother's age likely is not simply linear in its impact, and the other features may interact as well.\n",
        "\n",
        "At the end, create at least *2* tables and *1* visualization to summarize your best model. Then (in writing) answer the following questions:\n",
        "\n",
        "- What characteristics of a mother indicate the highest likelihood of an at-risk (low weight) baby?\n",
        "- What can expectant mothers be told to help mitigate this risk?\n",
        "\n",
        "Note that second question is not exactly a data science question - and that's okay! You're not expected to be a medical expert, but it is a good exercise to do a little bit of digging into a particular domain and offer informal but informed opinions."
      ]
    },
    {
      "metadata": {
        "id": "HUWKv16FjZsY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "bwt_df = pd.read_csv('http://people.reed.edu/~jones/141/Bwt.dat')\n",
        "bwt_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dy5FkUZpkJT_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bwt_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ez8qPLojjlFf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO - your work here! Also, add text cells for written questions."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XY9JGAnJisdB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Resources and stretch goals"
      ]
    },
    {
      "metadata": {
        "id": "inFWXSpqmND5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Resources:\n",
        "- [statsmodels QuantReg example](http://www.statsmodels.org/dev/examples/notebooks/generated/quantile_regression.html)\n",
        "- [How Shopify used Quantile Regression in modeling risk](https://medium.com/data-shopify/how-shopify-capital-uses-quantile-regression-to-help-merchants-succeed-10ee1b36b17d)\n",
        "\n",
        "Stretch goals:\n",
        "- Find a dataset where you think quantile regression may be appropriate, and try both it and linear regression - compare/contrast their strengths/weaknesses, and write a summary for which you think is better for the situation and why\n",
        "- Check out [deep quantile regression](https://www.kdnuggets.com/2018/07/deep-quantile-regression.html), an approach that uses a custom quantile loss function and Keras to train a quantile model"
      ]
    }
  ]
}
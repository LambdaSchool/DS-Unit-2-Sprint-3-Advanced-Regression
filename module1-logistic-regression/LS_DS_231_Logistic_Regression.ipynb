{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_231_Logistic_Regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "E7-AOngjadRN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ed-chin-git/DS-Unit-2-Sprint-3-Advanced-Regression/blob/master/module1-logistic-regression/LS_DS_231_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "N7SXF6jEBd5_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lambda School Data Science - Logistic Regression\n",
        "\n",
        "Logistic regression is the baseline for classification models, as well as a handy way to predict probabilities (since those too live in the unit interval). While relatively simple, it is also the foundation for more sophisticated classification techniques such as neural networks (many of which can effectively be thought of as networks of logistic models)."
      ]
    },
    {
      "metadata": {
        "id": "E7-AOngjadRN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lecture - Where Linear goes Wrong\n",
        "### Return of the Titanic 🚢\n",
        "\n",
        "You've likely already explored the rich dataset that is the Titanic - let's use regression and try to predict survival with it. The data is [available from Kaggle](https://www.kaggle.com/c/titanic/data), so we'll also play a bit with [the Kaggle API](https://github.com/Kaggle/kaggle-api)."
      ]
    },
    {
      "metadata": {
        "id": "MnHLWPYDcyIe",
        "colab_type": "code",
        "outputId": "f449dc52-82af-43ec-c6f7-f3f3aa028f13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.1.1)\n",
            "Requirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.11.29)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.0.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: Unidecode>=0.04.16 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.0.23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wPgce-jQc5zi",
        "colab_type": "code",
        "outputId": "19ed81f8-1e4e-485d-c9f0-be8076ef2e55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "# Note - you'll also have to sign up for Kaggle and authorize the API\n",
        "# https://github.com/Kaggle/kaggle-api#api-credentials\n",
        "\n",
        "# This essentially means uploading a kaggle.json file\n",
        "# For Colab we can have it in Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%env KAGGLE_CONFIG_DIR=/content/drive/My Drive/\n",
        "\n",
        "# You also have to join the Titanic competition to have access to the data\n",
        "!kaggle competitions download -c titanic"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "env: KAGGLE_CONFIG_DIR=/content/drive/My Drive/\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 11, in <module>\n",
            "    load_entry_point('kaggle==1.5.1.1', 'console_scripts', 'kaggle')()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/pkg_resources/__init__.py\", line 487, in load_entry_point\n",
            "    return get_distribution(dist).load_entry_point(group, name)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/pkg_resources/__init__.py\", line 2728, in load_entry_point\n",
            "    return ep.load()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/pkg_resources/__init__.py\", line 2346, in load\n",
            "    return self.resolve()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/pkg_resources/__init__.py\", line 2352, in resolve\n",
            "    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 116, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /content/drive/My Drive/. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-PtztP8YlFym",
        "colab_type": "code",
        "outputId": "b70a20e9-dfb8-4449-95e2-b3ee6fe4f1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        }
      },
      "cell_type": "code",
      "source": [
        "# How would we try to do this with linear regression?\n",
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('train.csv').dropna()\n",
        "test_df = pd.read_csv('test.csv').dropna()  # Unlabeled, for Kaggle submission\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6c763993cb4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Unlabeled, for Kaggle submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: File b'train.csv' does not exist"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Ey2ZHrGW_n_t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QiZn2p1K8DED",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X = train_df[['Pclass', 'Age', 'Fare']]\n",
        "y = train_df.Survived\n",
        "\n",
        "linear_reg = LinearRegression().fit(X, y)\n",
        "linear_reg.score(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8HsBb1hp_cev",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "linear_reg.predict(test_df[['Pclass', 'Age', 'Fare']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fcxfpsjdFJwM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "linear_reg.coef_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AFiisZU7_2Fr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "test_case = np.array([[1, 5, 500]])  # Rich 5-year old in first class\n",
        "linear_reg.predict(test_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dpUm8Dl-u2aB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression().fit(X, y)\n",
        "log_reg.score(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cUhr2c66F_th",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log_reg.predict(test_df[['Pclass', 'Age', 'Fare']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r7xWwqBrFuWL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log_reg.predict(test_case)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IM8g42clF2-6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "help(log_reg.predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "flF3pcMHGGWw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log_reg.predict_proba(test_case)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Bq-54noR1uE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# What's the math?\n",
        "log_reg.coef_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tj0mNL7_XWNV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log_reg.intercept_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AroeYscqR75f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The logistic sigmoid \"squishing\" function, implemented to accept numpy arrays\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.e**(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "804BA7s0SggQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sigmoid(log_reg.intercept_ + np.dot(log_reg.coef_, np.transpose(test_case)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uBSGY-R-Hf_b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So, clearly a more appropriate model in this situation! For more on the math, [see this Wikipedia example](https://en.wikipedia.org/wiki/Logistic_regression#Probability_of_passing_an_exam_versus_hours_of_study).\n",
        "\n",
        "For live - let's tackle [another classification dataset on absenteeism](http://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work) - it has 21 classes, but remember, scikit-learn LogisticRegression automatically handles more than two classes. How? By essentially treating each label as different (1) from some base class (0)."
      ]
    },
    {
      "metadata": {
        "id": "qyDBpCM0G7Hv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Live - let's try absenteeism!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iblW74C8afuR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assignment - real-world classification\n",
        "\n",
        "We're going to check out a larger dataset - the [FMA Free Music Archive data](https://github.com/mdeff/fma). It has a selection of CSVs with metadata and calculated audio features that you can load and try to use to classify genre of tracks. To get you started:"
      ]
    },
    {
      "metadata": {
        "id": "56sJsTKFbEYN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SsySnuKaKtQf",
        "colab_type": "code",
        "outputId": "a5cf5f7a-f048-46e8-dad3-5837ad135e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n",
        "!unzip fma_metadata.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-23 14:56:33--  https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n",
            "Resolving os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)... 86.119.28.13, 2001:620:5ca1:2ff::ce53\n",
            "Connecting to os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)|86.119.28.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 358412441 (342M) [application/zip]\n",
            "Saving to: ‘fma_metadata.zip’\n",
            "\n",
            "fma_metadata.zip    100%[===================>] 341.81M  26.1MB/s    in 14s     \n",
            "\n",
            "2019-01-23 14:56:48 (24.6 MB/s) - ‘fma_metadata.zip’ saved [358412441/358412441]\n",
            "\n",
            "Archive:  fma_metadata.zip\n",
            " bunzipping: fma_metadata/README.txt  \n",
            " bunzipping: fma_metadata/checksums  \n",
            " bunzipping: fma_metadata/not_found.pickle  \n",
            " bunzipping: fma_metadata/raw_genres.csv  \n",
            " bunzipping: fma_metadata/raw_albums.csv  \n",
            " bunzipping: fma_metadata/raw_artists.csv  \n",
            " bunzipping: fma_metadata/raw_tracks.csv  \n",
            " bunzipping: fma_metadata/tracks.csv  \n",
            " bunzipping: fma_metadata/genres.csv  \n",
            " bunzipping: fma_metadata/raw_echonest.csv  \n",
            " bunzipping: fma_metadata/echonest.csv  \n",
            " bunzipping: fma_metadata/features.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VbUJKyI1LRwD",
        "colab_type": "code",
        "outputId": "a0ea211c-dcad-47ea-b8bd-ad8d3c6ea0ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "tracks = pd.read_csv('fma_metadata/tracks.csv')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,5,6,8,12,18,20,21,22,24,33,34,38,39,44,47,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ut-Zfhp2LjcS",
        "colab_type": "code",
        "outputId": "77f43af3-917e-44fa-a69d-d62c4f388659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "cell_type": "code",
      "source": [
        "tracks.describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>album</th>\n",
              "      <th>album.1</th>\n",
              "      <th>album.2</th>\n",
              "      <th>album.3</th>\n",
              "      <th>album.4</th>\n",
              "      <th>album.5</th>\n",
              "      <th>album.6</th>\n",
              "      <th>album.7</th>\n",
              "      <th>album.8</th>\n",
              "      <th>...</th>\n",
              "      <th>track.10</th>\n",
              "      <th>track.11</th>\n",
              "      <th>track.12</th>\n",
              "      <th>track.13</th>\n",
              "      <th>track.14</th>\n",
              "      <th>track.15</th>\n",
              "      <th>track.16</th>\n",
              "      <th>track.17</th>\n",
              "      <th>track.18</th>\n",
              "      <th>track.19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>106575</td>\n",
              "      <td>106575</td>\n",
              "      <td>103046</td>\n",
              "      <td>70295</td>\n",
              "      <td>15296</td>\n",
              "      <td>106575</td>\n",
              "      <td>106575</td>\n",
              "      <td>83150</td>\n",
              "      <td>106575</td>\n",
              "      <td>18061</td>\n",
              "      <td>...</td>\n",
              "      <td>2350</td>\n",
              "      <td>106575</td>\n",
              "      <td>15025</td>\n",
              "      <td>106488</td>\n",
              "      <td>106575</td>\n",
              "      <td>312</td>\n",
              "      <td>106575</td>\n",
              "      <td>1264</td>\n",
              "      <td>106575</td>\n",
              "      <td>106574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>106575</td>\n",
              "      <td>29</td>\n",
              "      <td>14341</td>\n",
              "      <td>3670</td>\n",
              "      <td>623</td>\n",
              "      <td>65</td>\n",
              "      <td>14929</td>\n",
              "      <td>11076</td>\n",
              "      <td>11351</td>\n",
              "      <td>761</td>\n",
              "      <td>...</td>\n",
              "      <td>1587</td>\n",
              "      <td>18977</td>\n",
              "      <td>45</td>\n",
              "      <td>114</td>\n",
              "      <td>15340</td>\n",
              "      <td>67</td>\n",
              "      <td>331</td>\n",
              "      <td>136</td>\n",
              "      <td>2452</td>\n",
              "      <td>94987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>864</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-01-26 13:04:57</td>\n",
              "      <td>2008-01-01 00:00:00</td>\n",
              "      <td>Ernie Indradat</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>&lt;p class=\"p1\" style=\"margin: 0px; padding: 8px...</td>\n",
              "      <td>-1</td>\n",
              "      <td>Joe Belock</td>\n",
              "      <td>...</td>\n",
              "      <td>&lt;p&gt;&lt;a href=\"http://www.myspace.com/theshambler...</td>\n",
              "      <td>320</td>\n",
              "      <td>en</td>\n",
              "      <td>Attribution-Noncommercial-Share Alike 3.0 Unit...</td>\n",
              "      <td>97</td>\n",
              "      <td>Apache Tomcat</td>\n",
              "      <td>1</td>\n",
              "      <td>Victrola Dog (ASCAP)</td>\n",
              "      <td>[]</td>\n",
              "      <td>Untitled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>71187</td>\n",
              "      <td>310</td>\n",
              "      <td>667</td>\n",
              "      <td>876</td>\n",
              "      <td>45753</td>\n",
              "      <td>805</td>\n",
              "      <td>310</td>\n",
              "      <td>3130</td>\n",
              "      <td>855</td>\n",
              "      <td>...</td>\n",
              "      <td>22</td>\n",
              "      <td>67</td>\n",
              "      <td>14255</td>\n",
              "      <td>19250</td>\n",
              "      <td>110</td>\n",
              "      <td>44</td>\n",
              "      <td>10459</td>\n",
              "      <td>465</td>\n",
              "      <td>83078</td>\n",
              "      <td>298</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 53 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0   album              album.1              album.2  \\\n",
              "count      106575  106575               103046                70295   \n",
              "unique     106575      29                14341                 3670   \n",
              "top           864       0  2015-01-26 13:04:57  2008-01-01 00:00:00   \n",
              "freq            1   71187                  310                  667   \n",
              "\n",
              "               album.3  album.4  album.5  \\\n",
              "count            15296   106575   106575   \n",
              "unique             623       65    14929   \n",
              "top     Ernie Indradat        0       -1   \n",
              "freq               876    45753      805   \n",
              "\n",
              "                                                  album.6  album.7  \\\n",
              "count                                               83150   106575   \n",
              "unique                                              11076    11351   \n",
              "top     <p class=\"p1\" style=\"margin: 0px; padding: 8px...       -1   \n",
              "freq                                                  310     3130   \n",
              "\n",
              "           album.8    ...     \\\n",
              "count        18061    ...      \n",
              "unique         761    ...      \n",
              "top     Joe Belock    ...      \n",
              "freq           855    ...      \n",
              "\n",
              "                                                 track.10 track.11  track.12  \\\n",
              "count                                                2350   106575     15025   \n",
              "unique                                               1587    18977        45   \n",
              "top     <p><a href=\"http://www.myspace.com/theshambler...      320        en   \n",
              "freq                                                   22       67     14255   \n",
              "\n",
              "                                                 track.13 track.14  \\\n",
              "count                                              106488   106575   \n",
              "unique                                                114    15340   \n",
              "top     Attribution-Noncommercial-Share Alike 3.0 Unit...       97   \n",
              "freq                                                19250      110   \n",
              "\n",
              "             track.15 track.16              track.17  track.18  track.19  \n",
              "count             312   106575                  1264    106575    106574  \n",
              "unique             67      331                   136      2452     94987  \n",
              "top     Apache Tomcat        1  Victrola Dog (ASCAP)        []  Untitled  \n",
              "freq               44    10459                   465     83078       298  \n",
              "\n",
              "[4 rows x 53 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "_qzn-IjIM1Pw",
        "colab_type": "code",
        "outputId": "e47bf576-3201-4f32-d2e6-cdfc35776682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)  # Unlimited columns\n",
        "tracks.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>album</th>\n",
              "      <th>album.1</th>\n",
              "      <th>album.2</th>\n",
              "      <th>album.3</th>\n",
              "      <th>album.4</th>\n",
              "      <th>album.5</th>\n",
              "      <th>album.6</th>\n",
              "      <th>album.7</th>\n",
              "      <th>album.8</th>\n",
              "      <th>album.9</th>\n",
              "      <th>album.10</th>\n",
              "      <th>album.11</th>\n",
              "      <th>album.12</th>\n",
              "      <th>artist</th>\n",
              "      <th>artist.1</th>\n",
              "      <th>artist.2</th>\n",
              "      <th>artist.3</th>\n",
              "      <th>artist.4</th>\n",
              "      <th>artist.5</th>\n",
              "      <th>artist.6</th>\n",
              "      <th>artist.7</th>\n",
              "      <th>artist.8</th>\n",
              "      <th>artist.9</th>\n",
              "      <th>artist.10</th>\n",
              "      <th>artist.11</th>\n",
              "      <th>artist.12</th>\n",
              "      <th>artist.13</th>\n",
              "      <th>artist.14</th>\n",
              "      <th>artist.15</th>\n",
              "      <th>artist.16</th>\n",
              "      <th>set</th>\n",
              "      <th>set.1</th>\n",
              "      <th>track</th>\n",
              "      <th>track.1</th>\n",
              "      <th>track.2</th>\n",
              "      <th>track.3</th>\n",
              "      <th>track.4</th>\n",
              "      <th>track.5</th>\n",
              "      <th>track.6</th>\n",
              "      <th>track.7</th>\n",
              "      <th>track.8</th>\n",
              "      <th>track.9</th>\n",
              "      <th>track.10</th>\n",
              "      <th>track.11</th>\n",
              "      <th>track.12</th>\n",
              "      <th>track.13</th>\n",
              "      <th>track.14</th>\n",
              "      <th>track.15</th>\n",
              "      <th>track.16</th>\n",
              "      <th>track.17</th>\n",
              "      <th>track.18</th>\n",
              "      <th>track.19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>comments</td>\n",
              "      <td>date_created</td>\n",
              "      <td>date_released</td>\n",
              "      <td>engineer</td>\n",
              "      <td>favorites</td>\n",
              "      <td>id</td>\n",
              "      <td>information</td>\n",
              "      <td>listens</td>\n",
              "      <td>producer</td>\n",
              "      <td>tags</td>\n",
              "      <td>title</td>\n",
              "      <td>tracks</td>\n",
              "      <td>type</td>\n",
              "      <td>active_year_begin</td>\n",
              "      <td>active_year_end</td>\n",
              "      <td>associated_labels</td>\n",
              "      <td>bio</td>\n",
              "      <td>comments</td>\n",
              "      <td>date_created</td>\n",
              "      <td>favorites</td>\n",
              "      <td>id</td>\n",
              "      <td>latitude</td>\n",
              "      <td>location</td>\n",
              "      <td>longitude</td>\n",
              "      <td>members</td>\n",
              "      <td>name</td>\n",
              "      <td>related_projects</td>\n",
              "      <td>tags</td>\n",
              "      <td>website</td>\n",
              "      <td>wikipedia_page</td>\n",
              "      <td>split</td>\n",
              "      <td>subset</td>\n",
              "      <td>bit_rate</td>\n",
              "      <td>comments</td>\n",
              "      <td>composer</td>\n",
              "      <td>date_created</td>\n",
              "      <td>date_recorded</td>\n",
              "      <td>duration</td>\n",
              "      <td>favorites</td>\n",
              "      <td>genre_top</td>\n",
              "      <td>genres</td>\n",
              "      <td>genres_all</td>\n",
              "      <td>information</td>\n",
              "      <td>interest</td>\n",
              "      <td>language_code</td>\n",
              "      <td>license</td>\n",
              "      <td>listens</td>\n",
              "      <td>lyricist</td>\n",
              "      <td>number</td>\n",
              "      <td>publisher</td>\n",
              "      <td>tags</td>\n",
              "      <td>title</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>track_id</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:44:45</td>\n",
              "      <td>2009-01-05 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
              "      <td>6073</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>AWOL - A Way Of Life</td>\n",
              "      <td>7</td>\n",
              "      <td>Album</td>\n",
              "      <td>2006-01-01 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:42:32</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>40.0583238</td>\n",
              "      <td>New Jersey</td>\n",
              "      <td>-74.4056612</td>\n",
              "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>The list of past projects is 2 long but every1...</td>\n",
              "      <td>['awol']</td>\n",
              "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>training</td>\n",
              "      <td>small</td>\n",
              "      <td>256000</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2008-11-26 01:48:12</td>\n",
              "      <td>2008-11-26 00:00:00</td>\n",
              "      <td>168</td>\n",
              "      <td>2</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>[21]</td>\n",
              "      <td>[21]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4656</td>\n",
              "      <td>en</td>\n",
              "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
              "      <td>1293</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>Food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:44:45</td>\n",
              "      <td>2009-01-05 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
              "      <td>6073</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>AWOL - A Way Of Life</td>\n",
              "      <td>7</td>\n",
              "      <td>Album</td>\n",
              "      <td>2006-01-01 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:42:32</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>40.0583238</td>\n",
              "      <td>New Jersey</td>\n",
              "      <td>-74.4056612</td>\n",
              "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>The list of past projects is 2 long but every1...</td>\n",
              "      <td>['awol']</td>\n",
              "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>training</td>\n",
              "      <td>medium</td>\n",
              "      <td>256000</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2008-11-26 01:48:14</td>\n",
              "      <td>2008-11-26 00:00:00</td>\n",
              "      <td>237</td>\n",
              "      <td>1</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>[21]</td>\n",
              "      <td>[21]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1470</td>\n",
              "      <td>en</td>\n",
              "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
              "      <td>514</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>Electric Ave</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:44:45</td>\n",
              "      <td>2009-01-05 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
              "      <td>6073</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>AWOL - A Way Of Life</td>\n",
              "      <td>7</td>\n",
              "      <td>Album</td>\n",
              "      <td>2006-01-01 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:42:32</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>40.0583238</td>\n",
              "      <td>New Jersey</td>\n",
              "      <td>-74.4056612</td>\n",
              "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>The list of past projects is 2 long but every1...</td>\n",
              "      <td>['awol']</td>\n",
              "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>training</td>\n",
              "      <td>small</td>\n",
              "      <td>256000</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2008-11-26 01:48:20</td>\n",
              "      <td>2008-11-26 00:00:00</td>\n",
              "      <td>206</td>\n",
              "      <td>6</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>[21]</td>\n",
              "      <td>[21]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1933</td>\n",
              "      <td>en</td>\n",
              "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
              "      <td>1151</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>This World</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0     album              album.1              album.2   album.3  \\\n",
              "0        NaN  comments         date_created        date_released  engineer   \n",
              "1   track_id       NaN                  NaN                  NaN       NaN   \n",
              "2          2         0  2008-11-26 01:44:45  2009-01-05 00:00:00       NaN   \n",
              "3          3         0  2008-11-26 01:44:45  2009-01-05 00:00:00       NaN   \n",
              "4          5         0  2008-11-26 01:44:45  2009-01-05 00:00:00       NaN   \n",
              "\n",
              "     album.4 album.5      album.6  album.7   album.8 album.9  \\\n",
              "0  favorites      id  information  listens  producer    tags   \n",
              "1        NaN     NaN          NaN      NaN       NaN     NaN   \n",
              "2          4       1      <p></p>     6073       NaN      []   \n",
              "3          4       1      <p></p>     6073       NaN      []   \n",
              "4          4       1      <p></p>     6073       NaN      []   \n",
              "\n",
              "               album.10 album.11 album.12               artist  \\\n",
              "0                 title   tracks     type    active_year_begin   \n",
              "1                   NaN      NaN      NaN                  NaN   \n",
              "2  AWOL - A Way Of Life        7    Album  2006-01-01 00:00:00   \n",
              "3  AWOL - A Way Of Life        7    Album  2006-01-01 00:00:00   \n",
              "4  AWOL - A Way Of Life        7    Album  2006-01-01 00:00:00   \n",
              "\n",
              "          artist.1           artist.2  \\\n",
              "0  active_year_end  associated_labels   \n",
              "1              NaN                NaN   \n",
              "2              NaN                NaN   \n",
              "3              NaN                NaN   \n",
              "4              NaN                NaN   \n",
              "\n",
              "                                            artist.3  artist.4  \\\n",
              "0                                                bio  comments   \n",
              "1                                                NaN       NaN   \n",
              "2  <p>A Way Of Life, A Collective of Hip-Hop from...         0   \n",
              "3  <p>A Way Of Life, A Collective of Hip-Hop from...         0   \n",
              "4  <p>A Way Of Life, A Collective of Hip-Hop from...         0   \n",
              "\n",
              "              artist.5   artist.6 artist.7    artist.8    artist.9  \\\n",
              "0         date_created  favorites       id    latitude    location   \n",
              "1                  NaN        NaN      NaN         NaN         NaN   \n",
              "2  2008-11-26 01:42:32          9        1  40.0583238  New Jersey   \n",
              "3  2008-11-26 01:42:32          9        1  40.0583238  New Jersey   \n",
              "4  2008-11-26 01:42:32          9        1  40.0583238  New Jersey   \n",
              "\n",
              "     artist.10                                          artist.11 artist.12  \\\n",
              "0    longitude                                            members      name   \n",
              "1          NaN                                                NaN       NaN   \n",
              "2  -74.4056612  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...      AWOL   \n",
              "3  -74.4056612  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...      AWOL   \n",
              "4  -74.4056612  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...      AWOL   \n",
              "\n",
              "                                           artist.13 artist.14  \\\n",
              "0                                   related_projects      tags   \n",
              "1                                                NaN       NaN   \n",
              "2  The list of past projects is 2 long but every1...  ['awol']   \n",
              "3  The list of past projects is 2 long but every1...  ['awol']   \n",
              "4  The list of past projects is 2 long but every1...  ['awol']   \n",
              "\n",
              "                                 artist.15       artist.16       set   set.1  \\\n",
              "0                                  website  wikipedia_page     split  subset   \n",
              "1                                      NaN             NaN       NaN     NaN   \n",
              "2  http://www.AzillionRecords.blogspot.com             NaN  training   small   \n",
              "3  http://www.AzillionRecords.blogspot.com             NaN  training  medium   \n",
              "4  http://www.AzillionRecords.blogspot.com             NaN  training   small   \n",
              "\n",
              "      track   track.1   track.2              track.3              track.4  \\\n",
              "0  bit_rate  comments  composer         date_created        date_recorded   \n",
              "1       NaN       NaN       NaN                  NaN                  NaN   \n",
              "2    256000         0       NaN  2008-11-26 01:48:12  2008-11-26 00:00:00   \n",
              "3    256000         0       NaN  2008-11-26 01:48:14  2008-11-26 00:00:00   \n",
              "4    256000         0       NaN  2008-11-26 01:48:20  2008-11-26 00:00:00   \n",
              "\n",
              "    track.5    track.6    track.7 track.8     track.9     track.10  track.11  \\\n",
              "0  duration  favorites  genre_top  genres  genres_all  information  interest   \n",
              "1       NaN        NaN        NaN     NaN         NaN          NaN       NaN   \n",
              "2       168          2    Hip-Hop    [21]        [21]          NaN      4656   \n",
              "3       237          1    Hip-Hop    [21]        [21]          NaN      1470   \n",
              "4       206          6    Hip-Hop    [21]        [21]          NaN      1933   \n",
              "\n",
              "        track.12                                           track.13 track.14  \\\n",
              "0  language_code                                            license  listens   \n",
              "1            NaN                                                NaN      NaN   \n",
              "2             en  Attribution-NonCommercial-ShareAlike 3.0 Inter...     1293   \n",
              "3             en  Attribution-NonCommercial-ShareAlike 3.0 Inter...      514   \n",
              "4             en  Attribution-NonCommercial-ShareAlike 3.0 Inter...     1151   \n",
              "\n",
              "   track.15 track.16   track.17 track.18      track.19  \n",
              "0  lyricist   number  publisher     tags         title  \n",
              "1       NaN      NaN        NaN      NaN           NaN  \n",
              "2       NaN        3        NaN       []          Food  \n",
              "3       NaN        4        NaN       []  Electric Ave  \n",
              "4       NaN        6        NaN       []    This World  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "5DvMPiM8MZeY",
        "colab_type": "code",
        "outputId": "9ecdff77-0d46-4e17-fbfc-c0e5ec380572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tracks.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106574, 53)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "JQ34IVSoKJuy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "outputId": "dd25d6a2-2ec9-431e-9a95-7ec3d74948d0"
      },
      "cell_type": "code",
      "source": [
        "# existing column names are categories album/artist/track\n",
        "# rows 0 is metadata for the catergory\n",
        "# row 1 has 'track Id' column name for feature[0] \n",
        "features = tracks.iloc[0,:]  # load em into a list\n",
        "features[0] = 'track_id'     # track_id in row[1], insert manually \n",
        "tracks.columns = features    #  rename the DF column names\n",
        "tracks.drop([0,1], axis=0, inplace=True) #  drop row 0 and 1"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-8e30e5f3878d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'track_id'\u001b[0m     \u001b[0;31m# track_id in row[1], insert manually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m    \u001b[0;31m#  rename the DF column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtracks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  drop row 0 and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3744\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: labels [0 1] not contained in axis"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "kQUVlUKQMPPW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is the biggest data you've played with so far, and while it does generally fit in Colab, it can take awhile to run. That's part of the challenge!\n",
        "\n",
        "Your tasks:\n",
        "- Clean up the variable names in the dataframe\n",
        "- Use logistic regression to fit a model predicting (primary/top) genre\n",
        "- Inspect, iterate, and improve your model\n",
        "- Answer the following questions (written, ~paragraph each):\n",
        "  - What are the best predictors of genre?\n",
        "  - What information isn't very useful for predicting genre?\n",
        "  - What surprised you the most about your results?\n",
        "\n",
        "*Important caveats*:\n",
        "- This is going to be difficult data to work with - don't let the perfect be the enemy of the good!\n",
        "- Be creative in cleaning it up - if the best way you know how to do it is download it locally and edit as a spreadsheet, that's OK!\n",
        "- If the data size becomes problematic, consider sampling/subsetting\n",
        "- You do not need perfect or complete results - just something plausible that runs, and that supports the reasoning in your written answers\n",
        "\n",
        "If you find that fitting a model to classify *all* genres isn't very good, it's totally OK to limit to the most frequent genres, or perhaps trying to combine or cluster genres as a preprocessing step. Even then, there will be limits to how good a model can be with just this metadata - if you really want to train an effective genre classifier, you'll have to involve the other data (see stretch goals).\n",
        "\n",
        "This is real data - there is no \"one correct answer\", so you can take this in a variety of directions. Just make sure to support your findings, and feel free to share them as well! This is meant to be practice for dealing with other \"messy\" data, a common task in data science."
      ]
    },
    {
      "metadata": {
        "id": "wlI5OXfSag9C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Resources and stretch goals\n",
        "\n",
        "- Check out the other .csv files from the FMA dataset, and see if you can join them or otherwise fit interesting models with them\n",
        "- [Logistic regression from scratch in numpy](https://blog.goodaudience.com/logistic-regression-from-scratch-in-numpy-5841c09e425f) - if you want to dig in a bit more to both the code and math (also takes a gradient descent approach, introducing the logistic loss function)\n",
        "- Create a visualization to show predictions of your model - ideally show a confidence interval based on error!\n",
        "- Check out and compare classification models from scikit-learn, such as [SVM](https://scikit-learn.org/stable/modules/svm.html#classification), [decision trees](https://scikit-learn.org/stable/modules/tree.html#classification), and [naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html). The underlying math will vary significantly, but the API (how you write the code) and interpretation will actually be fairly similar.\n",
        "- Sign up for [Kaggle](https://kaggle.com), and find a competition to try logistic regression with\n",
        "- (Not logistic regression related) If you enjoyed the assignment, you may want to read up on [music informatics](https://en.wikipedia.org/wiki/Music_informatics), which is how those audio features were actually calculated. The FMA includes the actual raw audio, so (while this is more of a longterm project than a stretch goal, and won't fit in Colab) if you'd like you can check those out and see what sort of deeper analysis you can do."
      ]
    }
  ]
}
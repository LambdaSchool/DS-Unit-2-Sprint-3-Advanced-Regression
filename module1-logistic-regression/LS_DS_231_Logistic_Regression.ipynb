{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N7SXF6jEBd5_"
   },
   "source": [
    "# Lambda School Data Science - Logistic Regression\n",
    "\n",
    "Logistic regression is the baseline for classification models, as well as a handy way to predict probabilities (since those too live in the unit interval). While relatively simple, it is also the foundation for more sophisticated classification techniques such as neural networks (many of which can effectively be thought of as networks of logistic models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7-AOngjadRN"
   },
   "source": [
    "## Lecture - Where Linear goes Wrong\n",
    "### Return of the Titanic ðŸš¢\n",
    "\n",
    "You've likely already explored the rich dataset that is the Titanic - let's use regression and try to predict survival with it. The data is [available from Kaggle](https://www.kaggle.com/c/titanic/data), so we'll also play a bit with [the Kaggle API](https://github.com/Kaggle/kaggle-api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MnHLWPYDcyIe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading https://files.pythonhosted.org/packages/80/4d/fc83980735a7a2e3aaba1ed755462e839c68ba51ac311efdb1ab413a4eeb/kaggle-1.5.2.tar.gz (54kB)\n",
      "Collecting urllib3<1.23.0,>=1.15 (from kaggle)\n",
      "  Downloading https://files.pythonhosted.org/packages/63/cb/6965947c13a94236f6d4b8223e21beb4d576dc72e8130bd7880f600839b8/urllib3-1.22-py2.py3-none-any.whl (132kB)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\jhump\\anaconda3\\lib\\site-packages (from kaggle) (1.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\jhump\\anaconda3\\lib\\site-packages (from kaggle) (2018.10.15)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\jhump\\anaconda3\\lib\\site-packages (from kaggle) (2.7.3)\n",
      "Requirement already satisfied: requests in c:\\users\\jhump\\anaconda3\\lib\\site-packages (from kaggle) (2.19.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jhump\\anaconda3\\lib\\site-packages (from kaggle) (4.26.0)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/9c/8b07d625e9c9df567986d887f0375075abb1923e49d074a7803cd1527dae/python-slugify-2.0.1.tar.gz\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in c:\\users\\jhump\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\jhump\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.0.4)\n",
      "Collecting Unidecode>=0.04.16 (from python-slugify->kaggle)\n",
      "  Downloading https://files.pythonhosted.org/packages/31/39/53096f9217b057cb049fe872b7fc7ce799a1a89b76cf917d9639e7a558b5/Unidecode-1.0.23-py2.py3-none-any.whl (237kB)\n",
      "Building wheels for collected packages: kaggle, python-slugify\n",
      "  Running setup.py bdist_wheel for kaggle: started\n",
      "  Running setup.py bdist_wheel for kaggle: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\jhump\\AppData\\Local\\pip\\Cache\\wheels\\0d\\58\\eb\\83d6a2e1935aff39d341ffa1e5faa3809e173cd0937e057d83\n",
      "  Running setup.py bdist_wheel for python-slugify: started\n",
      "  Running setup.py bdist_wheel for python-slugify: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\jhump\\AppData\\Local\\pip\\Cache\\wheels\\2b\\9e\\c8\\14a18ab55d8f144384de8186a3df8401dcc9264936f71d470f\n",
      "Successfully built kaggle python-slugify\n",
      "Installing collected packages: urllib3, Unidecode, python-slugify, kaggle\n",
      "  Found existing installation: urllib3 1.23\n",
      "    Uninstalling urllib3-1.23:\n",
      "      Successfully uninstalled urllib3-1.23\n",
      "Successfully installed Unidecode-1.0.23 kaggle-1.5.2 python-slugify-2.0.1 urllib3-1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wPgce-jQc5zi"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-959ae15964a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# This essentially means uploading a kaggle.json file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# For Colab we can have it in Google Drive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'env'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'KAGGLE_CONFIG_DIR=/content/drive/My Drive/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# Note - you'll also have to sign up for Kaggle and authorize the API\n",
    "# https://github.com/Kaggle/kaggle-api#api-credentials\n",
    "\n",
    "# This essentially means uploading a kaggle.json file\n",
    "# For Colab we can have it in Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%env KAGGLE_CONFIG_DIR=/content/drive/My Drive/\n",
    "\n",
    "# You also have to join the Titanic competition to have access to the data\n",
    "!kaggle competitions download -c titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-PtztP8YlFym"
   },
   "outputs": [],
   "source": [
    "# How would we try to do this with linear regression?\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train.csv').dropna()\n",
    "test_df = pd.read_csv('test.csv').dropna()  # Unlabeled, for Kaggle submission\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ey2ZHrGW_n_t"
   },
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QiZn2p1K8DED"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = train_df[['Pclass', 'Age', 'Fare']]\n",
    "y = train_df.Survived\n",
    "\n",
    "linear_reg = LinearRegression().fit(X, y)\n",
    "linear_reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8HsBb1hp_cev"
   },
   "outputs": [],
   "source": [
    "linear_reg.predict(test_df[['Pclass', 'Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fcxfpsjdFJwM"
   },
   "outputs": [],
   "source": [
    "linear_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFiisZU7_2Fr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_case = np.array([[1, 5, 500]])  # Rich 5-year old in first class\n",
    "linear_reg.predict(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpUm8Dl-u2aB"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression().fit(X, y)\n",
    "log_reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cUhr2c66F_th"
   },
   "outputs": [],
   "source": [
    "log_reg.predict(test_df[['Pclass', 'Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r7xWwqBrFuWL"
   },
   "outputs": [],
   "source": [
    "log_reg.predict(test_case)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IM8g42clF2-6"
   },
   "outputs": [],
   "source": [
    "help(log_reg.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "flF3pcMHGGWw"
   },
   "outputs": [],
   "source": [
    "log_reg.predict_proba(test_case)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Bq-54noR1uE"
   },
   "outputs": [],
   "source": [
    "# What's the math?\n",
    "log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tj0mNL7_XWNV"
   },
   "outputs": [],
   "source": [
    "log_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AroeYscqR75f"
   },
   "outputs": [],
   "source": [
    "# The logistic sigmoid \"squishing\" function, implemented to accept numpy arrays\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.e**(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "804BA7s0SggQ"
   },
   "outputs": [],
   "source": [
    "sigmoid(log_reg.intercept_ + np.dot(log_reg.coef_, np.transpose(test_case)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uBSGY-R-Hf_b"
   },
   "source": [
    "So, clearly a more appropriate model in this situation! For more on the math, [see this Wikipedia example](https://en.wikipedia.org/wiki/Logistic_regression#Probability_of_passing_an_exam_versus_hours_of_study).\n",
    "\n",
    "For live - let's tackle [another classification dataset on absenteeism](http://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work) - it has 21 classes, but remember, scikit-learn LogisticRegression automatically handles more than two classes. How? By essentially treating each label as different (1) from some base class (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyDBpCM0G7Hv"
   },
   "outputs": [],
   "source": [
    "# Live - let's try absenteeism!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iblW74C8afuR"
   },
   "source": [
    "## Assignment - real-world classification\n",
    "\n",
    "We're going to check out a larger dataset - the [FMA Free Music Archive data](https://github.com/mdeff/fma). It has a selection of CSVs with metadata and calculated audio features that you can load and try to use to classify genre of tracks. To get you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is the biggest data you've played with so far, and while it does generally fit in Colab, it can take awhile to run. That's part of the challenge!\n",
    "\n",
    "Your tasks:\n",
    "- Clean up the variable names in the dataframe\n",
    "- Use logistic regression to fit a model predicting (primary/top) genre\n",
    "- Inspect, iterate, and improve your model\n",
    "- Answer the following questions (written, ~paragraph each):\n",
    "  - What are the best predictors of genre?\n",
    "  - What information isn't very useful for predicting genre?\n",
    "  - What surprised you the most about your results?\n",
    "\n",
    "*Important caveats*:\n",
    "- This is going to be difficult data to work with - don't let the perfect be the enemy of the good!\n",
    "- Be creative in cleaning it up - if the best way you know how to do it is download it locally and edit as a spreadsheet, that's OK!\n",
    "- If the data size becomes problematic, consider sampling/subsetting\n",
    "- You do not need perfect or complete results - just something plausible that runs, and that supports the reasoning in your written answers\n",
    "\n",
    "If you find that fitting a model to classify *all* genres isn't very good, it's totally OK to limit to the most frequent genres, or perhaps trying to combine or cluster genres as a preprocessing step. Even then, there will be limits to how good a model can be with just this metadata - if you really want to train an effective genre classifier, you'll have to involve the other data (see stretch goals).\n",
    "\n",
    "This is real data - there is no \"one correct answer\", so you can take this in a variety of directions. Just make sure to support your findings, and feel free to share them as well! This is meant to be practice for dealing with other \"messy\" data, a common task in data science.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !scp /c/users/jhump/Downloads/fma_metadata.zip -- does not return zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SsySnuKaKtQf"
   },
   "outputs": [],
   "source": [
    "# !unzip fma_metadata.zip -- not needed with local workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 942
    },
    "colab_type": "code",
    "id": "RGnO22FVr9iV",
    "outputId": "f70a3224-cf83-481c-99c2-9af466c585ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhump\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (0,1,5,6,8,12,18,20,21,22,24,33,34,38,39,44,47,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tracks = pd.read_csv('C:\\\\Users\\\\jhump\\\\Desktop\\\\fma_metadata\\\\tracks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "ut-Zfhp2LjcS",
    "outputId": "7aec97b7-2f05-4e9d-db32-f1125a46ba8c"
   },
   "outputs": [],
   "source": [
    "tracks.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "id": "_qzn-IjIM1Pw",
    "outputId": "23c73ee8-9d1d-4d6a-d4c4-87f7d6754dbf"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # Unlimited columns\n",
    "# tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "5DvMPiM8MZeY",
    "outputId": "999cd004-b5f8-433f-f26a-2d930abad0f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106576, 53)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1125
    },
    "colab_type": "code",
    "id": "DH3OO1beuj1S",
    "outputId": "e5f4ca08-7de4-4989-dc37-e80e67df1a9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_released</th>\n",
       "      <th>engineer</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>information</th>\n",
       "      <th>listens</th>\n",
       "      <th>producer</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>tracks</th>\n",
       "      <th>type</th>\n",
       "      <th>active_year_begin</th>\n",
       "      <th>active_year_end</th>\n",
       "      <th>associated_labels</th>\n",
       "      <th>bio</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>location</th>\n",
       "      <th>longitude</th>\n",
       "      <th>members</th>\n",
       "      <th>name</th>\n",
       "      <th>related_projects</th>\n",
       "      <th>tags</th>\n",
       "      <th>website</th>\n",
       "      <th>wikipedia_page</th>\n",
       "      <th>split</th>\n",
       "      <th>subset</th>\n",
       "      <th>bit_rate</th>\n",
       "      <th>comments</th>\n",
       "      <th>composer</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>duration</th>\n",
       "      <th>favorites</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres_all</th>\n",
       "      <th>information</th>\n",
       "      <th>interest</th>\n",
       "      <th>language_code</th>\n",
       "      <th>license</th>\n",
       "      <th>listens</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>number</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0583238</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.4056612</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:12</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4656</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0583238</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.4056612</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>medium</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:14</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1470</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Electric Ave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0583238</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.4056612</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:20</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>206</td>\n",
       "      <td>6</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1933</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>This World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:45:08</td>\n",
       "      <td>2008-02-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Constant Hitmaker</td>\n",
       "      <td>2</td>\n",
       "      <td>Album</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexican Summer, Richie Records, Woodsist, Skul...</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-family:Verdana, Geneva, A...</td>\n",
       "      <td>3</td>\n",
       "      <td>2008-11-26 01:42:55</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kurt Vile, the Violators</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['philly', 'kurt vile']</td>\n",
       "      <td>http://kurtvile.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>192000</td>\n",
       "      <td>0</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>2008-11-25 17:49:06</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>161</td>\n",
       "      <td>178</td>\n",
       "      <td>Pop</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54881</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>50135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Freeway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:45:05</td>\n",
       "      <td>2009-01-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;Â \"spiritual songs\" from Nicky Cook&lt;/p&gt;</td>\n",
       "      <td>2710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Niris</td>\n",
       "      <td>13</td>\n",
       "      <td>Album</td>\n",
       "      <td>1990-01-01 00:00:00</td>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Songs written by: Nicky Cook&lt;/p&gt;\\n&lt;p&gt;VOCALS...</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-11-26 01:42:52</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>51.895927</td>\n",
       "      <td>Colchester England</td>\n",
       "      <td>0.891874</td>\n",
       "      <td>Nicky Cook\\n</td>\n",
       "      <td>Nicky Cook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['instrumentals', 'experimental pop', 'post pu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:56</td>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[76, 103]</td>\n",
       "      <td>[17, 10, 76, 103]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>978</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Spiritual Level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 track_id comments         date_created        date_released engineer  \\\n",
       "2        2        0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "3        3        0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "4        5        0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "5       10        0  2008-11-26 01:45:08  2008-02-06 00:00:00      NaN   \n",
       "6       20        0  2008-11-26 01:45:05  2009-01-06 00:00:00      NaN   \n",
       "\n",
       "0 favorites id                                information listens producer  \\\n",
       "2         4  1                                    <p></p>    6073      NaN   \n",
       "3         4  1                                    <p></p>    6073      NaN   \n",
       "4         4  1                                    <p></p>    6073      NaN   \n",
       "5         4  6                                        NaN   47632      NaN   \n",
       "6         2  4  <p>Â \"spiritual songs\" from Nicky Cook</p>    2710      NaN   \n",
       "\n",
       "0 tags                 title tracks   type    active_year_begin  \\\n",
       "2   []  AWOL - A Way Of Life      7  Album  2006-01-01 00:00:00   \n",
       "3   []  AWOL - A Way Of Life      7  Album  2006-01-01 00:00:00   \n",
       "4   []  AWOL - A Way Of Life      7  Album  2006-01-01 00:00:00   \n",
       "5   []     Constant Hitmaker      2  Album                  NaN   \n",
       "6   []                 Niris     13  Album  1990-01-01 00:00:00   \n",
       "\n",
       "0      active_year_end                                  associated_labels  \\\n",
       "2                  NaN                                                NaN   \n",
       "3                  NaN                                                NaN   \n",
       "4                  NaN                                                NaN   \n",
       "5                  NaN  Mexican Summer, Richie Records, Woodsist, Skul...   \n",
       "6  2011-01-01 00:00:00                                                NaN   \n",
       "\n",
       "0                                                bio comments  \\\n",
       "2  <p>A Way Of Life, A Collective of Hip-Hop from...        0   \n",
       "3  <p>A Way Of Life, A Collective of Hip-Hop from...        0   \n",
       "4  <p>A Way Of Life, A Collective of Hip-Hop from...        0   \n",
       "5  <p><span style=\"font-family:Verdana, Geneva, A...        3   \n",
       "6  <p>Songs written by: Nicky Cook</p>\\n<p>VOCALS...        2   \n",
       "\n",
       "0         date_created favorites id    latitude            location  \\\n",
       "2  2008-11-26 01:42:32         9  1  40.0583238          New Jersey   \n",
       "3  2008-11-26 01:42:32         9  1  40.0583238          New Jersey   \n",
       "4  2008-11-26 01:42:32         9  1  40.0583238          New Jersey   \n",
       "5  2008-11-26 01:42:55        74  6         NaN                 NaN   \n",
       "6  2008-11-26 01:42:52        10  4   51.895927  Colchester England   \n",
       "\n",
       "0    longitude                                            members        name  \\\n",
       "2  -74.4056612  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "3  -74.4056612  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "4  -74.4056612  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "5          NaN                           Kurt Vile, the Violators   Kurt Vile   \n",
       "6     0.891874                                       Nicky Cook\\n  Nicky Cook   \n",
       "\n",
       "0                                   related_projects  \\\n",
       "2  The list of past projects is 2 long but every1...   \n",
       "3  The list of past projects is 2 long but every1...   \n",
       "4  The list of past projects is 2 long but every1...   \n",
       "5                                                NaN   \n",
       "6                                                NaN   \n",
       "\n",
       "0                                               tags  \\\n",
       "2                                           ['awol']   \n",
       "3                                           ['awol']   \n",
       "4                                           ['awol']   \n",
       "5                            ['philly', 'kurt vile']   \n",
       "6  ['instrumentals', 'experimental pop', 'post pu...   \n",
       "\n",
       "0                                  website wikipedia_page     split  subset  \\\n",
       "2  http://www.AzillionRecords.blogspot.com            NaN  training   small   \n",
       "3  http://www.AzillionRecords.blogspot.com            NaN  training  medium   \n",
       "4  http://www.AzillionRecords.blogspot.com            NaN  training   small   \n",
       "5                      http://kurtvile.com            NaN  training   small   \n",
       "6                                      NaN            NaN  training   large   \n",
       "\n",
       "0 bit_rate comments   composer         date_created        date_recorded  \\\n",
       "2   256000        0        NaN  2008-11-26 01:48:12  2008-11-26 00:00:00   \n",
       "3   256000        0        NaN  2008-11-26 01:48:14  2008-11-26 00:00:00   \n",
       "4   256000        0        NaN  2008-11-26 01:48:20  2008-11-26 00:00:00   \n",
       "5   192000        0  Kurt Vile  2008-11-25 17:49:06  2008-11-26 00:00:00   \n",
       "6   256000        0        NaN  2008-11-26 01:48:56  2008-01-01 00:00:00   \n",
       "\n",
       "0 duration favorites genre_top     genres         genres_all information  \\\n",
       "2      168         2   Hip-Hop       [21]               [21]         NaN   \n",
       "3      237         1   Hip-Hop       [21]               [21]         NaN   \n",
       "4      206         6   Hip-Hop       [21]               [21]         NaN   \n",
       "5      161       178       Pop       [10]               [10]         NaN   \n",
       "6      311         0       NaN  [76, 103]  [17, 10, 76, 103]         NaN   \n",
       "\n",
       "0 interest language_code                                            license  \\\n",
       "2     4656            en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "3     1470            en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "4     1933            en  Attribution-NonCommercial-ShareAlike 3.0 Inter...   \n",
       "5    54881            en  Attribution-NonCommercial-NoDerivatives (aka M...   \n",
       "6      978            en  Attribution-NonCommercial-NoDerivatives (aka M...   \n",
       "\n",
       "0 listens lyricist number publisher tags            title  \n",
       "2    1293      NaN      3       NaN   []             Food  \n",
       "3     514      NaN      4       NaN   []     Electric Ave  \n",
       "4    1151      NaN      6       NaN   []       This World  \n",
       "5   50135      NaN      1       NaN   []          Freeway  \n",
       "6     361      NaN      3       NaN   []  Spiritual Level  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tracks_copy = tracks.copy()\n",
    "new_header = tracks_copy.iloc[0]\n",
    "tracks_copy = tracks_copy[1:]\n",
    "tracks_copy.columns = new_header\n",
    "tracks_copy = tracks_copy.rename(columns={np.nan: 'track_id'})\n",
    "tracks_copy = tracks_copy.drop(index=[1])\n",
    "tracks_copy.head()\n",
    "# tracks_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1008
    },
    "colab_type": "code",
    "id": "NjWLlPN33F2r",
    "outputId": "dc17fdb2-9d48-4ac1-849b-993a5f8dfc76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'track_id',\n",
       " 1: 'comments',\n",
       " 2: 'date_created',\n",
       " 3: 'date_released',\n",
       " 4: 'engineer',\n",
       " 5: 'favorites',\n",
       " 6: 'id',\n",
       " 7: 'information',\n",
       " 8: 'listens',\n",
       " 9: 'producer',\n",
       " 10: 'tags',\n",
       " 11: 'title',\n",
       " 12: 'tracks',\n",
       " 13: 'type',\n",
       " 14: 'active_year_begin',\n",
       " 15: 'active_year_end',\n",
       " 16: 'associated_labels',\n",
       " 17: 'bio',\n",
       " 18: 'comments',\n",
       " 19: 'date_created',\n",
       " 20: 'favorites',\n",
       " 21: 'id',\n",
       " 22: 'latitude',\n",
       " 23: 'location',\n",
       " 24: 'longitude',\n",
       " 25: 'members',\n",
       " 26: 'name',\n",
       " 27: 'related_projects',\n",
       " 28: 'tags',\n",
       " 29: 'website',\n",
       " 30: 'wikipedia_page',\n",
       " 31: 'split',\n",
       " 32: 'subset',\n",
       " 33: 'bit_rate',\n",
       " 34: 'comments',\n",
       " 35: 'composer',\n",
       " 36: 'date_created',\n",
       " 37: 'date_recorded',\n",
       " 38: 'duration',\n",
       " 39: 'favorites',\n",
       " 40: 'genre_top',\n",
       " 41: 'genres',\n",
       " 42: 'genres_all',\n",
       " 43: 'information',\n",
       " 44: 'interest',\n",
       " 45: 'language_code',\n",
       " 46: 'license',\n",
       " 47: 'listens',\n",
       " 48: 'lyricist',\n",
       " 49: 'number',\n",
       " 50: 'publisher',\n",
       " 51: 'tags',\n",
       " 52: 'title'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_copy.columns\n",
    "tracks_copy_cols_map = zip([_ for _ in range(53)], tracks_copy.columns)\n",
    "tracks_copy_cols_dict = dict(tracks_copy_cols_map)\n",
    "tracks_copy_cols_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ybuvamM_SDV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['track_id',\n",
       " 'comments',\n",
       " 'date_created',\n",
       " 'date_released',\n",
       " 'engineer',\n",
       " 'favorites',\n",
       " 'id',\n",
       " 'information',\n",
       " 'listens',\n",
       " 'producer',\n",
       " 'tags',\n",
       " 'title',\n",
       " 'tracks',\n",
       " 'type',\n",
       " 'active_year_begin',\n",
       " 'active_year_end',\n",
       " 'associated_labels',\n",
       " 'bio',\n",
       " 'comments',\n",
       " 'date_created',\n",
       " 'favorites',\n",
       " 'id',\n",
       " 'latitude',\n",
       " 'location',\n",
       " 'longitude',\n",
       " 'members',\n",
       " 'name',\n",
       " 'related_projects',\n",
       " 'tags',\n",
       " 'website',\n",
       " 'wikipedia_page',\n",
       " 'split',\n",
       " 'subset',\n",
       " 'bit_rate',\n",
       " 'comments',\n",
       " 'composer',\n",
       " 'date_created',\n",
       " 'date_recorded',\n",
       " 'duration',\n",
       " 'favorites',\n",
       " 'genre_top',\n",
       " 'genres',\n",
       " 'genres_all',\n",
       " 'information',\n",
       " 'interest',\n",
       " 'language_code',\n",
       " 'license',\n",
       " 'listens',\n",
       " 'lyricist',\n",
       " 'number',\n",
       " 'publisher',\n",
       " 'tags',\n",
       " 'title']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rearrange order of tracks_copy columns for more logical, informative appearance\n",
    "# tracks_copy = tracks_copy.iloc[0, 11, 2:11, 1, 12:52]\n",
    "cols = tracks_copy.columns.tolist()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "tMc-z1Q8EO5Z",
    "outputId": "b4b9fc06-2fa2-45b6-b21d-ddb426642ee8"
   },
   "outputs": [],
   "source": [
    "new_cols = (cols[0], cols[2:12], cols[1], cols[12:52])\n",
    "new_cols_list = []\n",
    "for col in new_cols:\n",
    "    new_cols_list.append(col)\n",
    "new_cols_list\n",
    "type('track_id')\n",
    "# note: will make this a stretch goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hip-Hop', 'Pop', nan, 'Rock', 'Experimental', 'Folk', 'Jazz',\n",
       "       'Electronic', 'Spoken', 'International', 'Soul-RnB', 'Blues',\n",
       "       'Country', 'Classical', 'Old-Time / Historic', 'Instrumental',\n",
       "       'Easy Listening'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_copy.genre_top.unique()\n",
    "# tracks_copy.producer.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mylist = list(tracks_copy.select_dtypes(include=['int64', 'float64']).columns)\n",
    "# mylist\n",
    "# tracks_copy.dtypes\n",
    "# tracks_copy.date_recorded.unique()\n",
    "tracks_copy['date_recorded'] = pd.to_numeric(list(tracks_copy['date_recorded']), errors='coerce')\n",
    "tracks_copy['date_recorded'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "# convert timestamp strings into MMDDHH integer\n",
    "# first, write function to do conversion\n",
    "\n",
    "def convert_timestamp_to_int(val):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/54046862/python-convert-timestamp-string-to-mmddhh-integer\n",
    "    \"\"\"\n",
    "    date_string = dt.datetime.strptime(val, '%Y-%m-%d %H:%M:%S')\n",
    "    different_date_string = dt.datetime.strftime(date_string, '%m%d%H')\n",
    "    return int(different_date_string)\n",
    "\n",
    "# second, apply function to all values in date_recorded column\n",
    "tracks_copy['date_recorded'] = tracks_copy['date_recorded'].apply(convert_timestamp_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "track_id                  0\n",
       "comments                  0\n",
       "date_created           3529\n",
       "date_released         36280\n",
       "engineer              91279\n",
       "favorites                 0\n",
       "id                        0\n",
       "information           23425\n",
       "listens                   0\n",
       "producer              88514\n",
       "tags                      0\n",
       "title                  1025\n",
       "tracks                    0\n",
       "type                   6508\n",
       "active_year_begin     83863\n",
       "active_year_end      101199\n",
       "associated_labels     92303\n",
       "bio                   35418\n",
       "comments                  0\n",
       "date_created            856\n",
       "favorites                 0\n",
       "id                        0\n",
       "latitude              62030\n",
       "location              36364\n",
       "longitude             62030\n",
       "members               59725\n",
       "name                      0\n",
       "related_projects      93422\n",
       "tags                      0\n",
       "website               27318\n",
       "wikipedia_page       100993\n",
       "split                     0\n",
       "subset                    0\n",
       "bit_rate                  0\n",
       "comments                  0\n",
       "composer             102904\n",
       "date_created              0\n",
       "date_recorded        100415\n",
       "duration                  0\n",
       "favorites                 0\n",
       "genre_top             56976\n",
       "genres                    0\n",
       "genres_all                0\n",
       "information          104225\n",
       "interest                  0\n",
       "language_code         91550\n",
       "license                  87\n",
       "listens                   0\n",
       "lyricist             106263\n",
       "number                    0\n",
       "publisher            105311\n",
       "tags                      0\n",
       "title                     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_copy.isna().sum()\n",
    "# tracks_copy.tracks = tracks_copy.tracks.astype(int)\n",
    "# tracks_copy.tracks.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['date_created_threesix'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-6538f4755f97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# preprocess and generate data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtracks_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date_created_threesix'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'duration'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tracks'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtracks_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenre_top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2680\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2682\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2683\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2726\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2727\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['date_created_threesix'] not in index\""
     ]
    }
   ],
   "source": [
    "# build Logistic Regression model to predict \"genre_top\" for any given album\n",
    "# one way to do this involves converting string column names to numeric names - was unable to do this in efficient time\n",
    "# another preprocessing route that is faster is to go with columns that are already numeric\n",
    "# NOTE: ** denotes CREDIT to Zach Angell/LSDS01\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "# **\n",
    "tracks_copy[1] = 'comments_album'\n",
    "# tracks_copy[6] = 'id_col_6'\n",
    "tracks_copy[34] = 'comments_track'\n",
    "tracks_copy[36] = 'date_created_threesix'\n",
    "\n",
    "# would've liked to have used 'language_code', but tracks_copy.language_code.isna().sum() = 91550\n",
    "tracks_copy.duration = tracks_copy.duration.astype(float)\n",
    "# ** - drop nan's from genre_top, and date_created_36 values\n",
    "tracks_copy = tracks_copy[tracks_copy['genre_top'].notnull()]\n",
    "\n",
    "\n",
    "# preprocess and generate data\n",
    "X = tracks_copy[['date_created_threesix', 'duration', 'tracks']]\n",
    "y = tracks_copy.genre_top\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.50, random_state=42)\n",
    "\n",
    "'''\n",
    "ValueError: could not convert string to float: \"['ballad', 'epic', 'rockabilly', 'curse', 'hex', 'hard rock', 'cauldron', 'witches', 'creepy', 'black cats']\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([         'track_id',          'comments',      'date_created',\n",
       "           'date_released',          'engineer',         'favorites',\n",
       "                      'id',       'information',           'listens',\n",
       "                'producer',              'tags',             'title',\n",
       "                  'tracks',              'type', 'active_year_begin',\n",
       "         'active_year_end', 'associated_labels',               'bio',\n",
       "                'comments',      'date_created',         'favorites',\n",
       "                      'id',          'latitude',          'location',\n",
       "               'longitude',           'members',              'name',\n",
       "        'related_projects',              'tags',           'website',\n",
       "          'wikipedia_page',             'split',            'subset',\n",
       "                'bit_rate',          'comments',          'composer',\n",
       "            'date_created',     'date_recorded',          'duration',\n",
       "               'favorites',         'genre_top',            'genres',\n",
       "              'genres_all',       'information',          'interest',\n",
       "           'language_code',           'license',           'listens',\n",
       "                'lyricist',            'number',         'publisher',\n",
       "                    'tags',             'title',                   1,\n",
       "                        34,                  36],\n",
       "      dtype='object', name=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_train = LogisticRegression().fit(X_train, y_train)\n",
    "print('score for training data:', log_reg_train.score(X_train, y_train))\n",
    "\n",
    "log_reg_test = LogisticRegression().fit(X_test, y_test)\n",
    "print('score for testing data:', log_reg_test.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, look at the simple majority classifier for y_test **\n",
    "y_test.value_counts(normalize=True)\n",
    "\n",
    "# Comment: my initial LogReg model is more highly predictive than the SMC, but only by about 6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.predict(y_test[[]])\n",
    "log_reg.coef_\n",
    "log_reg.intercept_\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.e**(-x))\n",
    "\n",
    "# need to create test_case\n",
    "# sigmoid(log_reg.intercept_ + np.dot(log_reg.coef_, np.transpose(test_case)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kQUVlUKQMPPW"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlI5OXfSag9C"
   },
   "source": [
    "## Resources and stretch goals\n",
    "\n",
    "- Check out the other .csv files from the FMA dataset, and see if you can join them or otherwise fit interesting models with them\n",
    "- [Logistic regression from scratch in numpy](https://blog.goodaudience.com/logistic-regression-from-scratch-in-numpy-5841c09e425f) - if you want to dig in a bit more to both the code and math (also takes a gradient descent approach, introducing the logistic loss function)\n",
    "- Create a visualization to show predictions of your model - ideally show a confidence interval based on error!\n",
    "- Check out and compare classification models from scikit-learn, such as [SVM](https://scikit-learn.org/stable/modules/svm.html#classification), [decision trees](https://scikit-learn.org/stable/modules/tree.html#classification), and [naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html). The underlying math will vary significantly, but the API (how you write the code) and interpretation will actually be fairly similar.\n",
    "- Sign up for [Kaggle](https://kaggle.com), and find a competition to try logistic regression with\n",
    "- (Not logistic regression related) If you enjoyed the assignment, you may want to read up on [music informatics](https://en.wikipedia.org/wiki/Music_informatics), which is how those audio features were actually calculated. The FMA includes the actual raw audio, so (while this is more of a longterm project than a stretch goal, and won't fit in Colab) if you'd like you can check those out and see what sort of deeper analysis you can do."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_231_Logistic_Regression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

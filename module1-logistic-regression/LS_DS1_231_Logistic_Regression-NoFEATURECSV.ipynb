{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N7SXF6jEBd5_"
   },
   "source": [
    "# Lambda School Data Science - Logistic Regression\n",
    "\n",
    "Logistic regression is the baseline for classification models, as well as a handy way to predict probabilities (since those too live in the unit interval). While relatively simple, it is also the foundation for more sophisticated classification techniques such as neural networks (many of which can effectively be thought of as networks of logistic models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iblW74C8afuR"
   },
   "source": [
    "## Assignment - real-world classification\n",
    "\n",
    "We're going to check out a larger dataset - the [FMA Free Music Archive data](https://github.com/mdeff/fma). It has a selection of CSVs with metadata and calculated audio features that you can load and try to use to classify genre of tracks. To get you started:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vjTUO22lMG0i"
   },
   "source": [
    "### First I'll download all the data and set a few parameters for Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yA_4xiW2MyY8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)  # Unlimited columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SsySnuKaKtQf"
   },
   "outputs": [],
   "source": [
    "#!wget https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n",
    "#!unzip fma_metadata.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vpo9YbWsL4Ln"
   },
   "source": [
    "### Now I'll open the Tracks.csv and create my dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "VbUJKyI1LRwD",
    "outputId": "408c0b8e-4a10-41cd-88f6-2af7351685bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>album</th>\n",
       "      <th>album.1</th>\n",
       "      <th>album.2</th>\n",
       "      <th>album.3</th>\n",
       "      <th>album.4</th>\n",
       "      <th>album.5</th>\n",
       "      <th>album.6</th>\n",
       "      <th>album.7</th>\n",
       "      <th>album.8</th>\n",
       "      <th>album.9</th>\n",
       "      <th>album.10</th>\n",
       "      <th>album.11</th>\n",
       "      <th>album.12</th>\n",
       "      <th>artist</th>\n",
       "      <th>artist.1</th>\n",
       "      <th>artist.2</th>\n",
       "      <th>artist.3</th>\n",
       "      <th>artist.4</th>\n",
       "      <th>artist.5</th>\n",
       "      <th>artist.6</th>\n",
       "      <th>artist.7</th>\n",
       "      <th>artist.8</th>\n",
       "      <th>artist.9</th>\n",
       "      <th>artist.10</th>\n",
       "      <th>artist.11</th>\n",
       "      <th>artist.12</th>\n",
       "      <th>artist.13</th>\n",
       "      <th>artist.14</th>\n",
       "      <th>artist.15</th>\n",
       "      <th>artist.16</th>\n",
       "      <th>set</th>\n",
       "      <th>set.1</th>\n",
       "      <th>track</th>\n",
       "      <th>track.1</th>\n",
       "      <th>track.2</th>\n",
       "      <th>track.3</th>\n",
       "      <th>track.4</th>\n",
       "      <th>track.5</th>\n",
       "      <th>track.6</th>\n",
       "      <th>track.7</th>\n",
       "      <th>track.8</th>\n",
       "      <th>track.9</th>\n",
       "      <th>track.10</th>\n",
       "      <th>track.11</th>\n",
       "      <th>track.12</th>\n",
       "      <th>track.13</th>\n",
       "      <th>track.14</th>\n",
       "      <th>track.15</th>\n",
       "      <th>track.16</th>\n",
       "      <th>track.17</th>\n",
       "      <th>track.18</th>\n",
       "      <th>track.19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>comments</td>\n",
       "      <td>date_created</td>\n",
       "      <td>date_released</td>\n",
       "      <td>engineer</td>\n",
       "      <td>favorites</td>\n",
       "      <td>id</td>\n",
       "      <td>information</td>\n",
       "      <td>listens</td>\n",
       "      <td>producer</td>\n",
       "      <td>tags</td>\n",
       "      <td>title</td>\n",
       "      <td>tracks</td>\n",
       "      <td>type</td>\n",
       "      <td>active_year_begin</td>\n",
       "      <td>active_year_end</td>\n",
       "      <td>associated_labels</td>\n",
       "      <td>bio</td>\n",
       "      <td>comments</td>\n",
       "      <td>date_created</td>\n",
       "      <td>favorites</td>\n",
       "      <td>id</td>\n",
       "      <td>latitude</td>\n",
       "      <td>location</td>\n",
       "      <td>longitude</td>\n",
       "      <td>members</td>\n",
       "      <td>name</td>\n",
       "      <td>related_projects</td>\n",
       "      <td>tags</td>\n",
       "      <td>website</td>\n",
       "      <td>wikipedia_page</td>\n",
       "      <td>split</td>\n",
       "      <td>subset</td>\n",
       "      <td>bit_rate</td>\n",
       "      <td>comments</td>\n",
       "      <td>composer</td>\n",
       "      <td>date_created</td>\n",
       "      <td>date_recorded</td>\n",
       "      <td>duration</td>\n",
       "      <td>favorites</td>\n",
       "      <td>genre_top</td>\n",
       "      <td>genres</td>\n",
       "      <td>genres_all</td>\n",
       "      <td>information</td>\n",
       "      <td>interest</td>\n",
       "      <td>language_code</td>\n",
       "      <td>license</td>\n",
       "      <td>listens</td>\n",
       "      <td>lyricist</td>\n",
       "      <td>number</td>\n",
       "      <td>publisher</td>\n",
       "      <td>tags</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>track_id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0583238</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.4056612</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:12</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4656</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0583238</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.4056612</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>medium</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:14</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1470</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Electric Ave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0583238</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.4056612</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:20</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>206</td>\n",
       "      <td>6</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1933</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>This World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0     album              album.1              album.2   album.3  \\\n",
       "0        NaN  comments         date_created        date_released  engineer   \n",
       "1   track_id       NaN                  NaN                  NaN       NaN   \n",
       "2          2         0  2008-11-26 01:44:45  2009-01-05 00:00:00       NaN   \n",
       "3          3         0  2008-11-26 01:44:45  2009-01-05 00:00:00       NaN   \n",
       "4          5         0  2008-11-26 01:44:45  2009-01-05 00:00:00       NaN   \n",
       "\n",
       "     album.4 album.5      album.6  album.7   album.8 album.9  \\\n",
       "0  favorites      id  information  listens  producer    tags   \n",
       "1        NaN     NaN          NaN      NaN       NaN     NaN   \n",
       "2          4       1      <p></p>     6073       NaN      []   \n",
       "3          4       1      <p></p>     6073       NaN      []   \n",
       "4          4       1      <p></p>     6073       NaN      []   \n",
       "\n",
       "               album.10 album.11 album.12               artist  \\\n",
       "0                 title   tracks     type    active_year_begin   \n",
       "1                   NaN      NaN      NaN                  NaN   \n",
       "2  AWOL - A Way Of Life        7    Album  2006-01-01 00:00:00   \n",
       "3  AWOL - A Way Of Life        7    Album  2006-01-01 00:00:00   \n",
       "4  AWOL - A Way Of Life        7    Album  2006-01-01 00:00:00   \n",
       "\n",
       "          artist.1           artist.2  \\\n",
       "0  active_year_end  associated_labels   \n",
       "1              NaN                NaN   \n",
       "2              NaN                NaN   \n",
       "3              NaN                NaN   \n",
       "4              NaN                NaN   \n",
       "\n",
       "                                            artist.3  artist.4  \\\n",
       "0                                                bio  comments   \n",
       "1                                                NaN       NaN   \n",
       "2  <p>A Way Of Life, A Collective of Hip-Hop from...         0   \n",
       "3  <p>A Way Of Life, A Collective of Hip-Hop from...         0   \n",
       "4  <p>A Way Of Life, A Collective of Hip-Hop from...         0   \n",
       "\n",
       "              artist.5   artist.6 artist.7    artist.8    artist.9  \\\n",
       "0         date_created  favorites       id    latitude    location   \n",
       "1                  NaN        NaN      NaN         NaN         NaN   \n",
       "2  2008-11-26 01:42:32          9        1  40.0583238  New Jersey   \n",
       "3  2008-11-26 01:42:32          9        1  40.0583238  New Jersey   \n",
       "4  2008-11-26 01:42:32          9        1  40.0583238  New Jersey   \n",
       "\n",
       "     artist.10                                          artist.11 artist.12  \\\n",
       "0    longitude                                            members      name   \n",
       "1          NaN                                                NaN       NaN   \n",
       "2  -74.4056612  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...      AWOL   \n",
       "3  -74.4056612  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...      AWOL   \n",
       "4  -74.4056612  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...      AWOL   \n",
       "\n",
       "                                           artist.13 artist.14  \\\n",
       "0                                   related_projects      tags   \n",
       "1                                                NaN       NaN   \n",
       "2  The list of past projects is 2 long but every1...  ['awol']   \n",
       "3  The list of past projects is 2 long but every1...  ['awol']   \n",
       "4  The list of past projects is 2 long but every1...  ['awol']   \n",
       "\n",
       "                                 artist.15       artist.16       set   set.1  \\\n",
       "0                                  website  wikipedia_page     split  subset   \n",
       "1                                      NaN             NaN       NaN     NaN   \n",
       "2  http://www.AzillionRecords.blogspot.com             NaN  training   small   \n",
       "3  http://www.AzillionRecords.blogspot.com             NaN  training  medium   \n",
       "4  http://www.AzillionRecords.blogspot.com             NaN  training   small   \n",
       "\n",
       "      track   track.1   track.2              track.3              track.4  \\\n",
       "0  bit_rate  comments  composer         date_created        date_recorded   \n",
       "1       NaN       NaN       NaN                  NaN                  NaN   \n",
       "2    256000         0       NaN  2008-11-26 01:48:12  2008-11-26 00:00:00   \n",
       "3    256000         0       NaN  2008-11-26 01:48:14  2008-11-26 00:00:00   \n",
       "4    256000         0       NaN  2008-11-26 01:48:20  2008-11-26 00:00:00   \n",
       "\n",
       "    track.5    track.6    track.7 track.8     track.9     track.10  track.11  \\\n",
       "0  duration  favorites  genre_top  genres  genres_all  information  interest   \n",
       "1       NaN        NaN        NaN     NaN         NaN          NaN       NaN   \n",
       "2       168          2    Hip-Hop    [21]        [21]          NaN      4656   \n",
       "3       237          1    Hip-Hop    [21]        [21]          NaN      1470   \n",
       "4       206          6    Hip-Hop    [21]        [21]          NaN      1933   \n",
       "\n",
       "        track.12                                           track.13 track.14  \\\n",
       "0  language_code                                            license  listens   \n",
       "1            NaN                                                NaN      NaN   \n",
       "2             en  Attribution-NonCommercial-ShareAlike 3.0 Inter...     1293   \n",
       "3             en  Attribution-NonCommercial-ShareAlike 3.0 Inter...      514   \n",
       "4             en  Attribution-NonCommercial-ShareAlike 3.0 Inter...     1151   \n",
       "\n",
       "   track.15 track.16   track.17 track.18      track.19  \n",
       "0  lyricist   number  publisher     tags         title  \n",
       "1       NaN      NaN        NaN      NaN           NaN  \n",
       "2       NaN        3        NaN       []          Food  \n",
       "3       NaN        4        NaN       []  Electric Ave  \n",
       "4       NaN        6        NaN       []    This World  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading this CSV but the names of the columns look all messed up.\n",
    "names = pd.read_csv('fma_metadata/tracks.csv')\n",
    "names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eJY1oAl7MP_H"
   },
   "source": [
    "Ooh, those headers look all messed up. I'll replace them with a cleaner list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9O_EXAaMMWjB"
   },
   "source": [
    "### Replace headers with tidy list of good names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "colab_type": "code",
    "id": "_qzn-IjIM1Pw",
    "outputId": "f2c76d4f-db56-4b5b-975f-9d37124a4f70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fixed list of names now: ['track_id', 'comments', 'date_created'] ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_released</th>\n",
       "      <th>engineer</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>information</th>\n",
       "      <th>listens</th>\n",
       "      <th>producer</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>tracks</th>\n",
       "      <th>type</th>\n",
       "      <th>active_year_begin</th>\n",
       "      <th>active_year_end</th>\n",
       "      <th>associated_labels</th>\n",
       "      <th>bio</th>\n",
       "      <th>comments.1</th>\n",
       "      <th>date_created.1</th>\n",
       "      <th>favorites.1</th>\n",
       "      <th>id.1</th>\n",
       "      <th>latitude</th>\n",
       "      <th>location</th>\n",
       "      <th>longitude</th>\n",
       "      <th>members</th>\n",
       "      <th>name</th>\n",
       "      <th>related_projects</th>\n",
       "      <th>tags.1</th>\n",
       "      <th>website</th>\n",
       "      <th>wikipedia_page</th>\n",
       "      <th>split</th>\n",
       "      <th>subset</th>\n",
       "      <th>bit_rate</th>\n",
       "      <th>comments.2</th>\n",
       "      <th>composer</th>\n",
       "      <th>date_created.2</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>duration</th>\n",
       "      <th>favorites.2</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres_all</th>\n",
       "      <th>information.1</th>\n",
       "      <th>interest</th>\n",
       "      <th>language_code</th>\n",
       "      <th>license</th>\n",
       "      <th>listens.1</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>number</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags.2</th>\n",
       "      <th>title.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:12</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4656</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>medium</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:14</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1470</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Electric Ave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  comments         date_created        date_released engineer  \\\n",
       "0         2         0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "1         3         0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "\n",
       "   favorites  id information  listens producer tags                 title  \\\n",
       "0          4   1     <p></p>     6073      NaN   []  AWOL - A Way Of Life   \n",
       "1          4   1     <p></p>     6073      NaN   []  AWOL - A Way Of Life   \n",
       "\n",
       "   tracks   type    active_year_begin active_year_end associated_labels  \\\n",
       "0       7  Album  2006-01-01 00:00:00             NaN               NaN   \n",
       "1       7  Album  2006-01-01 00:00:00             NaN               NaN   \n",
       "\n",
       "                                                 bio  comments.1  \\\n",
       "0  <p>A Way Of Life, A Collective of Hip-Hop from...           0   \n",
       "1  <p>A Way Of Life, A Collective of Hip-Hop from...           0   \n",
       "\n",
       "        date_created.1  favorites.1  id.1   latitude    location  longitude  \\\n",
       "0  2008-11-26 01:42:32            9     1  40.058324  New Jersey -74.405661   \n",
       "1  2008-11-26 01:42:32            9     1  40.058324  New Jersey -74.405661   \n",
       "\n",
       "                                             members  name  \\\n",
       "0  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...  AWOL   \n",
       "1  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...  AWOL   \n",
       "\n",
       "                                    related_projects    tags.1  \\\n",
       "0  The list of past projects is 2 long but every1...  ['awol']   \n",
       "1  The list of past projects is 2 long but every1...  ['awol']   \n",
       "\n",
       "                                   website wikipedia_page     split  subset  \\\n",
       "0  http://www.AzillionRecords.blogspot.com            NaN  training   small   \n",
       "1  http://www.AzillionRecords.blogspot.com            NaN  training  medium   \n",
       "\n",
       "   bit_rate  comments.2 composer       date_created.2        date_recorded  \\\n",
       "0    256000           0      NaN  2008-11-26 01:48:12  2008-11-26 00:00:00   \n",
       "1    256000           0      NaN  2008-11-26 01:48:14  2008-11-26 00:00:00   \n",
       "\n",
       "   duration  favorites.2 genre_top genres genres_all information.1  interest  \\\n",
       "0       168            2   Hip-Hop   [21]       [21]           NaN      4656   \n",
       "1       237            1   Hip-Hop   [21]       [21]           NaN      1470   \n",
       "\n",
       "  language_code                                            license  listens.1  \\\n",
       "0            en  Attribution-NonCommercial-ShareAlike 3.0 Inter...       1293   \n",
       "1            en  Attribution-NonCommercial-ShareAlike 3.0 Inter...        514   \n",
       "\n",
       "  lyricist  number publisher tags.2       title.1  \n",
       "0      NaN       3       NaN     []          Food  \n",
       "1      NaN       4       NaN     []  Electric Ave  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So I need to make a list of the good names, and drop all the rows that aren't good. \n",
    "# I'm going to save these names and use them as the feature names.\n",
    "cols = names[0:1].values.tolist()\n",
    "cols = cols[0]\n",
    "cols[0] = 'track_id'\n",
    "print(f\"The fixed list of names now: {cols[0:3]} ...\\n\")\n",
    "\n",
    "# Instead of renaming these I'm going to reimport my csv and drop the top rows.\n",
    "# This way it will import the datatypes for each column\n",
    "tracks = pd.read_csv('fma_metadata/tracks.csv', skiprows=[0,1,2], header=None, names=cols)\n",
    "tracks.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tSIVxX3NFhP"
   },
   "source": [
    "### Inspect the data a bit more...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ut-Zfhp2LjcS",
    "outputId": "408ef921-8378-48eb-985c-b10e12790033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106574, 53)\n"
     ]
    }
   ],
   "source": [
    "print(tracks.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VgFYNPxGBEHi"
   },
   "source": [
    "### Here I'm going to add in the Features.csv field. \n",
    "\n",
    "These features are from the features extraction from the audio (used to create features.csv).\n",
    "https://github.com/mdeff/fma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xV5JRlUO3eO6"
   },
   "outputs": [],
   "source": [
    "#features = pd.read_csv('fma_metadata/features.csv', skiprows=[1,2,3])\n",
    "#features = features.rename(columns={'feature': 'track_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "qfMvaoP94k4m",
    "outputId": "00e24a68-8cc0-424f-8fd5-564a93ab335c"
   },
   "outputs": [],
   "source": [
    "# Here I printed out a longer head table to make sure that the rows allign.\n",
    "# I also print out the shape to make sure it looks right for mergeing the two dataframes. \n",
    "#print(features.shape)\n",
    "#features.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XyXoFjKKwV7l"
   },
   "source": [
    "### Merge Tracks and Features into one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdjx2CGbT8O1"
   },
   "outputs": [],
   "source": [
    "#df = pd.merge(tracks, features, on=['track_id', 'track_id'])\n",
    "df=tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "KRMX3wVKYog3",
    "outputId": "7764bafd-cb54-44e7-e0fc-36e9caeee1ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_released</th>\n",
       "      <th>engineer</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>information</th>\n",
       "      <th>listens</th>\n",
       "      <th>producer</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>tracks</th>\n",
       "      <th>type</th>\n",
       "      <th>active_year_begin</th>\n",
       "      <th>active_year_end</th>\n",
       "      <th>associated_labels</th>\n",
       "      <th>bio</th>\n",
       "      <th>comments.1</th>\n",
       "      <th>date_created.1</th>\n",
       "      <th>favorites.1</th>\n",
       "      <th>id.1</th>\n",
       "      <th>latitude</th>\n",
       "      <th>location</th>\n",
       "      <th>longitude</th>\n",
       "      <th>members</th>\n",
       "      <th>name</th>\n",
       "      <th>related_projects</th>\n",
       "      <th>tags.1</th>\n",
       "      <th>website</th>\n",
       "      <th>wikipedia_page</th>\n",
       "      <th>split</th>\n",
       "      <th>subset</th>\n",
       "      <th>bit_rate</th>\n",
       "      <th>comments.2</th>\n",
       "      <th>composer</th>\n",
       "      <th>date_created.2</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>duration</th>\n",
       "      <th>favorites.2</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres_all</th>\n",
       "      <th>information.1</th>\n",
       "      <th>interest</th>\n",
       "      <th>language_code</th>\n",
       "      <th>license</th>\n",
       "      <th>listens.1</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>number</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags.2</th>\n",
       "      <th>title.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:12</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4656</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>medium</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:14</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1470</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Electric Ave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:20</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>206</td>\n",
       "      <td>6</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1933</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>This World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:45:08</td>\n",
       "      <td>2008-02-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Constant Hitmaker</td>\n",
       "      <td>2</td>\n",
       "      <td>Album</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexican Summer, Richie Records, Woodsist, Skul...</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-family:Verdana, Geneva, A...</td>\n",
       "      <td>3</td>\n",
       "      <td>2008-11-26 01:42:55</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kurt Vile, the Violators</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['philly', 'kurt vile']</td>\n",
       "      <td>http://kurtvile.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>192000</td>\n",
       "      <td>0</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>2008-11-25 17:49:06</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>161</td>\n",
       "      <td>178</td>\n",
       "      <td>Pop</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54881</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>50135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Freeway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-11-26 01:45:05</td>\n",
       "      <td>2009-01-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt; \"spiritual songs\" from Nicky Cook&lt;/p&gt;</td>\n",
       "      <td>2710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Niris</td>\n",
       "      <td>13</td>\n",
       "      <td>Album</td>\n",
       "      <td>1990-01-01 00:00:00</td>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Songs written by: Nicky Cook&lt;/p&gt;\\n&lt;p&gt;VOCALS...</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-11-26 01:42:52</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>51.895927</td>\n",
       "      <td>Colchester England</td>\n",
       "      <td>0.891874</td>\n",
       "      <td>Nicky Cook\\n</td>\n",
       "      <td>Nicky Cook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['instrumentals', 'experimental pop', 'post pu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:56</td>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[76, 103]</td>\n",
       "      <td>[17, 10, 76, 103]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>978</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Spiritual Level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  comments         date_created        date_released engineer  \\\n",
       "0         2         0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "1         3         0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "2         5         0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "3        10         0  2008-11-26 01:45:08  2008-02-06 00:00:00      NaN   \n",
       "4        20         0  2008-11-26 01:45:05  2009-01-06 00:00:00      NaN   \n",
       "\n",
       "   favorites  id                                information  listens producer  \\\n",
       "0          4   1                                    <p></p>     6073      NaN   \n",
       "1          4   1                                    <p></p>     6073      NaN   \n",
       "2          4   1                                    <p></p>     6073      NaN   \n",
       "3          4   6                                        NaN    47632      NaN   \n",
       "4          2   4  <p> \"spiritual songs\" from Nicky Cook</p>     2710      NaN   \n",
       "\n",
       "  tags                 title  tracks   type    active_year_begin  \\\n",
       "0   []  AWOL - A Way Of Life       7  Album  2006-01-01 00:00:00   \n",
       "1   []  AWOL - A Way Of Life       7  Album  2006-01-01 00:00:00   \n",
       "2   []  AWOL - A Way Of Life       7  Album  2006-01-01 00:00:00   \n",
       "3   []     Constant Hitmaker       2  Album                  NaN   \n",
       "4   []                 Niris      13  Album  1990-01-01 00:00:00   \n",
       "\n",
       "       active_year_end                                  associated_labels  \\\n",
       "0                  NaN                                                NaN   \n",
       "1                  NaN                                                NaN   \n",
       "2                  NaN                                                NaN   \n",
       "3                  NaN  Mexican Summer, Richie Records, Woodsist, Skul...   \n",
       "4  2011-01-01 00:00:00                                                NaN   \n",
       "\n",
       "                                                 bio  comments.1  \\\n",
       "0  <p>A Way Of Life, A Collective of Hip-Hop from...           0   \n",
       "1  <p>A Way Of Life, A Collective of Hip-Hop from...           0   \n",
       "2  <p>A Way Of Life, A Collective of Hip-Hop from...           0   \n",
       "3  <p><span style=\"font-family:Verdana, Geneva, A...           3   \n",
       "4  <p>Songs written by: Nicky Cook</p>\\n<p>VOCALS...           2   \n",
       "\n",
       "        date_created.1  favorites.1  id.1   latitude            location  \\\n",
       "0  2008-11-26 01:42:32            9     1  40.058324          New Jersey   \n",
       "1  2008-11-26 01:42:32            9     1  40.058324          New Jersey   \n",
       "2  2008-11-26 01:42:32            9     1  40.058324          New Jersey   \n",
       "3  2008-11-26 01:42:55           74     6        NaN                 NaN   \n",
       "4  2008-11-26 01:42:52           10     4  51.895927  Colchester England   \n",
       "\n",
       "   longitude                                            members        name  \\\n",
       "0 -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "1 -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "2 -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "3        NaN                           Kurt Vile, the Violators   Kurt Vile   \n",
       "4   0.891874                                       Nicky Cook\\n  Nicky Cook   \n",
       "\n",
       "                                    related_projects  \\\n",
       "0  The list of past projects is 2 long but every1...   \n",
       "1  The list of past projects is 2 long but every1...   \n",
       "2  The list of past projects is 2 long but every1...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              tags.1  \\\n",
       "0                                           ['awol']   \n",
       "1                                           ['awol']   \n",
       "2                                           ['awol']   \n",
       "3                            ['philly', 'kurt vile']   \n",
       "4  ['instrumentals', 'experimental pop', 'post pu...   \n",
       "\n",
       "                                   website wikipedia_page     split  subset  \\\n",
       "0  http://www.AzillionRecords.blogspot.com            NaN  training   small   \n",
       "1  http://www.AzillionRecords.blogspot.com            NaN  training  medium   \n",
       "2  http://www.AzillionRecords.blogspot.com            NaN  training   small   \n",
       "3                      http://kurtvile.com            NaN  training   small   \n",
       "4                                      NaN            NaN  training   large   \n",
       "\n",
       "   bit_rate  comments.2   composer       date_created.2        date_recorded  \\\n",
       "0    256000           0        NaN  2008-11-26 01:48:12  2008-11-26 00:00:00   \n",
       "1    256000           0        NaN  2008-11-26 01:48:14  2008-11-26 00:00:00   \n",
       "2    256000           0        NaN  2008-11-26 01:48:20  2008-11-26 00:00:00   \n",
       "3    192000           0  Kurt Vile  2008-11-25 17:49:06  2008-11-26 00:00:00   \n",
       "4    256000           0        NaN  2008-11-26 01:48:56  2008-01-01 00:00:00   \n",
       "\n",
       "   duration  favorites.2 genre_top     genres         genres_all  \\\n",
       "0       168            2   Hip-Hop       [21]               [21]   \n",
       "1       237            1   Hip-Hop       [21]               [21]   \n",
       "2       206            6   Hip-Hop       [21]               [21]   \n",
       "3       161          178       Pop       [10]               [10]   \n",
       "4       311            0       NaN  [76, 103]  [17, 10, 76, 103]   \n",
       "\n",
       "  information.1  interest language_code  \\\n",
       "0           NaN      4656            en   \n",
       "1           NaN      1470            en   \n",
       "2           NaN      1933            en   \n",
       "3           NaN     54881            en   \n",
       "4           NaN       978            en   \n",
       "\n",
       "                                             license  listens.1 lyricist  \\\n",
       "0  Attribution-NonCommercial-ShareAlike 3.0 Inter...       1293      NaN   \n",
       "1  Attribution-NonCommercial-ShareAlike 3.0 Inter...        514      NaN   \n",
       "2  Attribution-NonCommercial-ShareAlike 3.0 Inter...       1151      NaN   \n",
       "3  Attribution-NonCommercial-NoDerivatives (aka M...      50135      NaN   \n",
       "4  Attribution-NonCommercial-NoDerivatives (aka M...        361      NaN   \n",
       "\n",
       "   number publisher tags.2          title.1  \n",
       "0       3       NaN     []             Food  \n",
       "1       4       NaN     []     Electric Ave  \n",
       "2       6       NaN     []       This World  \n",
       "3       1       NaN     []          Freeway  \n",
       "4       3       NaN     []  Spiritual Level  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rock                   14182\n",
      "Experimental           10608\n",
      "Electronic              9372\n",
      "Hip-Hop                 3552\n",
      "Folk                    2803\n",
      "Pop                     2332\n",
      "Instrumental            2079\n",
      "International           1389\n",
      "Classical               1230\n",
      "Jazz                     571\n",
      "Old-Time / Historic      554\n",
      "Spoken                   423\n",
      "Country                  194\n",
      "Soul-RnB                 175\n",
      "Blues                    110\n",
      "Easy Listening            24\n",
      "Name: genre_top, dtype: int64\n",
      "Rock             14182\n",
      "Experimental     10608\n",
      "Electronic        9372\n",
      "Hip-Hop           3552\n",
      "Folk              2803\n",
      "Pop               2332\n",
      "Instrumental      2079\n",
      "other             2051\n",
      "International     1389\n",
      "Classical         1230\n",
      "Name: genre_top, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "topgenre_unique = df['genre_top'].value_counts()\n",
    "print(topgenre_unique)\n",
    "#Country music? Not in my classifier. Hahaha\n",
    "replace_these = [\"Jazz\", \"Old-Time / Historic\", \"Spoken\", \"Soul-RnB\", \"Blues\", \"Country\",\"Easy Listening\"]\n",
    "for i in replace_these:\n",
    "    df[\"genre_top\"] = df['genre_top'].replace(i,\"other\")\n",
    "\n",
    "topgenre_unique = df['genre_top'].value_counts()\n",
    "print(topgenre_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qaPM3NK6KNef"
   },
   "source": [
    "### Now a bit of Feature Engineering on the merged DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "colab_type": "code",
    "id": "q_hJSjEiuu8o",
    "outputId": "9b5e77d2-fc8b-4f2c-d833-d28dc55aa7dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lyricist</th>\n",
       "      <td>106263</td>\n",
       "      <td>0.997082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publisher</th>\n",
       "      <td>105311</td>\n",
       "      <td>0.988149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>information.1</th>\n",
       "      <td>104225</td>\n",
       "      <td>0.977959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>composer</th>\n",
       "      <td>102904</td>\n",
       "      <td>0.965564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active_year_end</th>\n",
       "      <td>101199</td>\n",
       "      <td>0.949566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wikipedia_page</th>\n",
       "      <td>100993</td>\n",
       "      <td>0.947633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_recorded</th>\n",
       "      <td>100415</td>\n",
       "      <td>0.942209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>related_projects</th>\n",
       "      <td>93422</td>\n",
       "      <td>0.876593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>associated_labels</th>\n",
       "      <td>92303</td>\n",
       "      <td>0.866093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language_code</th>\n",
       "      <td>91550</td>\n",
       "      <td>0.859028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineer</th>\n",
       "      <td>91279</td>\n",
       "      <td>0.856485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>producer</th>\n",
       "      <td>88514</td>\n",
       "      <td>0.830540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active_year_begin</th>\n",
       "      <td>83863</td>\n",
       "      <td>0.786899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>62030</td>\n",
       "      <td>0.582037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>62030</td>\n",
       "      <td>0.582037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>members</th>\n",
       "      <td>59725</td>\n",
       "      <td>0.560409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_top</th>\n",
       "      <td>56976</td>\n",
       "      <td>0.534614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>36364</td>\n",
       "      <td>0.341209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_released</th>\n",
       "      <td>36280</td>\n",
       "      <td>0.340421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bio</th>\n",
       "      <td>35418</td>\n",
       "      <td>0.332332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>website</th>\n",
       "      <td>27318</td>\n",
       "      <td>0.256329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>information</th>\n",
       "      <td>23425</td>\n",
       "      <td>0.219800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>6508</td>\n",
       "      <td>0.061066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_created</th>\n",
       "      <td>3529</td>\n",
       "      <td>0.033113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>1025</td>\n",
       "      <td>0.009618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Total   Percent\n",
       "lyricist           106263  0.997082\n",
       "publisher          105311  0.988149\n",
       "information.1      104225  0.977959\n",
       "composer           102904  0.965564\n",
       "active_year_end    101199  0.949566\n",
       "wikipedia_page     100993  0.947633\n",
       "date_recorded      100415  0.942209\n",
       "related_projects    93422  0.876593\n",
       "associated_labels   92303  0.866093\n",
       "language_code       91550  0.859028\n",
       "engineer            91279  0.856485\n",
       "producer            88514  0.830540\n",
       "active_year_begin   83863  0.786899\n",
       "longitude           62030  0.582037\n",
       "latitude            62030  0.582037\n",
       "members             59725  0.560409\n",
       "genre_top           56976  0.534614\n",
       "location            36364  0.341209\n",
       "date_released       36280  0.340421\n",
       "bio                 35418  0.332332\n",
       "website             27318  0.256329\n",
       "information         23425  0.219800\n",
       "type                 6508  0.061066\n",
       "date_created         3529  0.033113\n",
       "title                1025  0.009618"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which columns are missing data\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "oJW7-7aGuqqX",
    "outputId": "51dd863a-1157-4210-f078-541a73c0dbec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         name  name_code\n",
      "0        AWOL        299\n",
      "1        AWOL        299\n",
      "2        AWOL        299\n",
      "3   Kurt Vile       7425\n",
      "4  Nicky Cook       9558\n",
      "5  Nicky Cook       9558\n",
      "6  Nicky Cook       9558\n",
      "7  Nicky Cook       9558\n",
      "8  Nicky Cook       9558\n",
      "9        AWOL        299\n",
      "    type  type_code\n",
      "0  Album          0\n",
      "1  Album          0\n",
      "2  Album          0\n",
      "3  Album          0\n",
      "4  Album          0\n",
      "5  Album          0\n",
      "6  Album          0\n",
      "7  Album          0\n",
      "8  Album          0\n",
      "9  Album          0\n",
      "       genre_top  genre_top_code\n",
      "0        Hip-Hop               4\n",
      "1        Hip-Hop               4\n",
      "2        Hip-Hop               4\n",
      "3            Pop               7\n",
      "9        Hip-Hop               4\n",
      "10          Rock               8\n",
      "11          Rock               8\n",
      "12  Experimental               2\n",
      "13  Experimental               2\n",
      "14          Folk               3\n"
     ]
    }
   ],
   "source": [
    "# Lets take some of the data and see if we can do some tricky feature engineering.\n",
    "\n",
    "# Here I'll use Label Encoding \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "# df['name'] Should encode this name. Categorical variable.\n",
    "#df = df.dropna(subset=['name'])\n",
    "df[\"name_code\"] = lb_make.fit_transform(df[\"name\"])\n",
    "print(df[[\"name\", \"name_code\"]].head(10))\n",
    "\n",
    "# df['type'] Should encode this name. Categorical variable.\n",
    "df = df.dropna(subset=['type'])\n",
    "df[\"type_code\"] = lb_make.fit_transform(df[\"type\"])\n",
    "print(df[[\"type\", \"type_code\"]].head(10))\n",
    "\n",
    "# df['genre_top'] Should encode this name. Categorical variable.\n",
    "df = df.dropna(subset=['genre_top'])\n",
    "df[\"genre_top_code\"] = lb_make.fit_transform(df[\"genre_top\"])\n",
    "print(df[[\"genre_top\", \"genre_top_code\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JGdoWnMDuLYn",
    "outputId": "53230f05-8102-4906-b931-5c629b6789f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47551, 56)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "LHIai56Rpedz",
    "outputId": "75ccb86f-db23-436c-a726-156566c79932"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>genre_top_code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_created</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total  Percent\n",
       "genre_top_code      0      0.0\n",
       "type_code           0      0.0\n",
       "comments            0      0.0\n",
       "date_created        0      0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop all remaining columns missing data. \n",
    "nan_columns = df.columns[df.isna().any()].tolist()\n",
    "df = df.drop(columns=nan_columns)\n",
    "df.head(1)\n",
    "\n",
    "# Make sure we didn't miss any.\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "HyUO5yf7ysqi",
    "outputId": "b6f3c94d-2420-452c-db9c-742bcf4f60e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>genre_top_code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_created</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total  Percent\n",
       "genre_top_code      0      0.0\n",
       "type_code           0      0.0\n",
       "comments            0      0.0\n",
       "date_created        0      0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which columns are missing data\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mPA6o1_Ky3Uo",
    "outputId": "feacc244-2156-42a5-9ba7-31e15d3c59ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47551, 19)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All my rows are dropped that will be dropped. Now I'll make my key lists for \n",
    "df_key= df[[\"genre_top\", \"genre_top_code\",\"type\", \"type_code\",\"name\", \"name_code\"]]\n",
    "\n",
    "# Lets drop all the non-numerical columns now. \n",
    "data = df._get_numeric_data()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exw3WTLJ0Gjp"
   },
   "source": [
    "### Now for some Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "upkz4qpF0FuB"
   },
   "outputs": [],
   "source": [
    "# Define my X & Y\n",
    "y=data[\"genre_top_code\"]\n",
    "X=data.drop(columns=['genre_top_code'])\n",
    "\n",
    "# Going to try a standard scaling my X for fast converge with SAG / SAGA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Here is where I split the model into test/train sets. \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                    test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7HXdoaP6z2T"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 207 epochs took 301 seconds\n",
      "convergence after 232 epochs took 335 seconds\n",
      "convergence after 250 epochs took 363 seconds\n",
      "convergence after 283 epochs took 410 seconds\n",
      "convergence after 283 epochs took 412 seconds\n",
      "convergence after 285 epochs took 418 seconds\n",
      "convergence after 294 epochs took 428 seconds\n",
      "convergence after 298 epochs took 435 seconds\n",
      "convergence after 303 epochs took 437 seconds\n",
      "convergence after 304 epochs took 448 seconds\n",
      "convergence after 355 epochs took 517 seconds\n",
      "convergence after 366 epochs took 534 seconds\n",
      "convergence after 451 epochs took 652 seconds\n",
      "convergence after 673 epochs took 974 seconds\n",
      "convergence after 352 epochs took 511 seconds\n",
      "convergence after 756 epochs took 1107 seconds\n",
      "convergence after 79 epochs took 115 seconds\n",
      "convergence after 825 epochs took 1194 seconds\n",
      "convergence after 75 epochs took 108 seconds\n",
      "convergence after 921 epochs took 1323 seconds\n",
      "convergence after 14 epochs took 19 seconds\n",
      "convergence after 926 epochs took 1329 seconds\n",
      "convergence after 10 epochs took 15 seconds\n",
      "convergence after 1150 epochs took 1653 seconds\n",
      "convergence after 1186 epochs took 1707 seconds\n",
      "convergence after 277 epochs took 404 seconds\n",
      "convergence after 1212 epochs took 1760 seconds\n",
      "convergence after 803 epochs took 1167 seconds\n",
      "convergence after 1351 epochs took 1945 seconds\n",
      "convergence after 663 epochs took 974 seconds\n",
      "convergence after 607 epochs took 880 seconds\n",
      "convergence after 1392 epochs took 2022 seconds\n",
      "convergence after 1541 epochs took 2235 seconds\n",
      "convergence after 202 epochs took 291 seconds\n",
      "convergence after 236 epochs took 348 seconds\n",
      "convergence after 341 epochs took 500 seconds\n",
      "convergence after 177 epochs took 252 seconds\n",
      "convergence after 948 epochs took 1373 seconds\n",
      "convergence after 28 epochs took 42 seconds\n",
      "convergence after 25 epochs took 38 seconds\n",
      "convergence after 211 epochs took 313 seconds\n",
      "convergence after 39 epochs took 59 seconds\n",
      "convergence after 727 epochs took 1067 seconds\n",
      "convergence after 27 epochs took 40 seconds\n",
      "convergence after 1150 epochs took 1668 seconds\n",
      "convergence after 368 epochs took 531 seconds\n",
      "convergence after 284 epochs took 415 seconds\n",
      "convergence after 67 epochs took 96 seconds\n",
      "convergence after 45 epochs took 66 seconds\n",
      "convergence after 384 epochs took 555 seconds\n",
      "convergence after 303 epochs took 443 seconds\n",
      "convergence after 1221 epochs took 1765 seconds\n",
      "convergence after 1360 epochs took 1957 seconds\n",
      "convergence after 259 epochs took 378 seconds\n",
      "convergence after 1249 epochs took 1827 seconds\n",
      "convergence after 353 epochs took 516 seconds\n",
      "convergence after 543 epochs took 781 seconds\n",
      "convergence after 662 epochs took 966 seconds\n",
      "convergence after 63 epochs took 90 seconds\n",
      "convergence after 42 epochs took 60 seconds\n",
      "convergence after 250 epochs took 359 seconds\n",
      "convergence after 494 epochs took 706 seconds\n",
      "convergence after 743 epochs took 1085 seconds\n",
      "convergence after 261 epochs took 366 seconds\n",
      "convergence after 510 epochs took 739 seconds\n",
      "convergence after 597 epochs took 853 seconds\n",
      "convergence after 1651 epochs took 2391 seconds\n",
      "convergence after 226 epochs took 326 seconds\n",
      "convergence after 38 epochs took 55 seconds\n",
      "convergence after 26 epochs took 37 seconds\n",
      "convergence after 1725 epochs took 2511 seconds\n",
      "convergence after 679 epochs took 970 seconds\n",
      "convergence after 78 epochs took 109 seconds\n",
      "convergence after 460 epochs took 660 seconds\n",
      "convergence after 253 epochs took 363 seconds\n",
      "convergence after 57 epochs took 83 seconds\n",
      "convergence after 79 epochs took 110 seconds\n",
      "convergence after 476 epochs took 681 seconds\n",
      "convergence after 54 epochs took 78 seconds\n",
      "convergence after 82 epochs took 119 seconds\n",
      "convergence after 671 epochs took 968 seconds\n",
      "convergence after 56 epochs took 81 seconds\n",
      "convergence after 577 epochs took 820 seconds\n",
      "convergence after 250 epochs took 352 seconds\n",
      "convergence after 1191 epochs took 1694 seconds\n",
      "convergence after 105 epochs took 135 seconds\n",
      "convergence after 252 epochs took 346 seconds\n",
      "convergence after 723 epochs took 1006 seconds\n",
      "convergence after 70 epochs took 83 seconds\n",
      "convergence after 251 epochs took 308 seconds\n",
      "convergence after 2329 epochs took 3289 seconds\n",
      "convergence after 1667 epochs took 2327 seconds\n",
      "convergence after 770 epochs took 998 seconds\n",
      "convergence after 226 epochs took 230 seconds\n",
      "convergence after 38 epochs took 39 seconds\n",
      "convergence after 26 epochs took 31 seconds\n",
      "convergence after 1315 epochs took 1667 seconds\n",
      "convergence after 931 epochs took 1103 seconds\n",
      "convergence after 819 epochs took 872 seconds\n",
      "convergence after 706 epochs took 729 seconds\n",
      "convergence after 792 epochs took 814 seconds\n",
      "convergence after 121 epochs took 108 seconds\n",
      "convergence after 84 epochs took 75 seconds\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'f1_score' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/basicNLP/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[0;34m(scoring)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'f1_score'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-cd6f47f77888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                 random_state=42)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mlogregCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/basicNLP/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1791\u001b[0m                       \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m                       )\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_encoded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m             for train, test in folds)\n\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basicNLP/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basicNLP/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basicNLP/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basicNLP/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basicNLP/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;31m# We capture the KeyboardInterrupt and reraise it as\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basicNLP/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basicNLP/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basicNLP/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_log_reg_scoring_path\u001b[0;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ovr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basicNLP/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[0;34m(scoring)\u001b[0m\n\u001b[1;32m    231\u001b[0m             raise ValueError('%r is not a valid scoring value. '\n\u001b[1;32m    232\u001b[0m                              \u001b[0;34m'Use sorted(sklearn.metrics.SCORERS.keys()) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                              'to get valid options.' % (scoring))\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'f1_score' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 758 epochs took 745 seconds\n",
      "convergence after 132 epochs took 100 seconds\n",
      "convergence after 92 epochs took 68 seconds\n",
      "convergence after 650 epochs took 497 seconds\n",
      "convergence after 1269 epochs took 1129 seconds\n",
      "convergence after 642 epochs took 479 seconds\n",
      "convergence after 203 epochs took 123 seconds\n",
      "convergence after 203 epochs took 123 seconds\n",
      "convergence after 178 epochs took 110 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Cross-Validation Logistic Regression to determine C hyperparameter\n",
    "logregCV = LogisticRegressionCV(Cs=[.01,.1,.5,1,5,10,30],\n",
    "                                cv=2,\n",
    "                                class_weight ='balanced', \n",
    "                                scoring='f1_score',\n",
    "                                solver='saga', \n",
    "                                max_iter=3000,\n",
    "                                n_jobs=-1, \n",
    "                                verbose=1,\n",
    "                                random_state=42)\n",
    "\n",
    "logregCV.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegressionCV' object has no attribute 'scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-48f6bcab5bba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Max auc_roc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogregCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogregCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegressionCV' object has no attribute 'scores_'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 31 epochs took 20 seconds\n",
      "convergence after 175 epochs took 108 seconds\n",
      "convergence after 21 epochs took 13 seconds\n",
      "convergence after 31 epochs took 16 seconds\n",
      "convergence after 21 epochs took 11 seconds\n",
      "convergence after 2038 epochs took 1686 seconds\n",
      "convergence after 2102 epochs took 1215 seconds\n",
      "convergence after 2529 epochs took 1638 seconds\n",
      "convergence after 1417 epochs took 606 seconds\n",
      "convergence after 937 epochs took 324 seconds\n",
      "convergence after 273 epochs took 95 seconds\n",
      "convergence after 192 epochs took 67 seconds\n",
      "convergence after 2926 epochs took 1527 seconds\n",
      "convergence after 1006 epochs took 262 seconds\n",
      "convergence after 1318 epochs took 347 seconds\n",
      "convergence after 1385 epochs took 367 seconds\n",
      "convergence after 196 epochs took 40 seconds\n",
      "convergence after 133 epochs took 26 seconds\n",
      "convergence after 1552 epochs took 224 seconds\n",
      "convergence after 1343 epochs took 132 seconds\n",
      "convergence after 1436 epochs took 143 seconds\n",
      "convergence after 254 epochs took 22 seconds\n",
      "convergence after 270 epochs took 23 seconds\n",
      "convergence after 178 epochs took 15 seconds\n",
      "convergence after 189 epochs took 8 seconds\n",
      "convergence after 1783 epochs took 83 seconds\n",
      "convergence after 342 epochs took 3 seconds\n",
      "convergence after 241 epochs took 1 seconds\n"
     ]
    }
   ],
   "source": [
    "print ('Max auc_roc:', logregCV.scores_[1].mean(axis=0).max()) \n",
    "y_predicted = logregCV.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vy7XcEmr7Bb9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "def get_metrics(y_test, y_predicted):  \n",
    "    # true positives / (true positives+false positives)\n",
    "    precision = precision_score(y_test, y_predicted, pos_label=None,\n",
    "                                    average='weighted')             \n",
    "    # true positives / (true positives + false negatives)\n",
    "    recall = recall_score(y_test, y_predicted, pos_label=None,\n",
    "                              average='weighted')\n",
    "    \n",
    "    # harmonic mean of precision and recall\n",
    "    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n",
    "    \n",
    "    # true positives + true negatives/ total\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_predicted)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see if we can find the ideal features.\n",
    "logreg = LogisticRegression(solver='saga', multi_class='auto', n_jobs=-1, \n",
    "                         random_state=42, verbose=1, max_iter=500, warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrT7bDQtzr-V",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "rfe = RFE(logreg, 20)\n",
    "rfe = rfe.fit(X_test, y_test)\n",
    "\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TISsxrXvrKe4"
   },
   "source": [
    "## Guidance for the Assignment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kQUVlUKQMPPW"
   },
   "source": [
    "This is the biggest data you've played with so far, and while it does generally fit in Colab, it can take awhile to run. That's part of the challenge!\n",
    "\n",
    "Your tasks:\n",
    "- Clean up the variable names in the dataframe\n",
    "- Use logistic regression to fit a model predicting (primary/top) genre\n",
    "- Inspect, iterate, and improve your model\n",
    "- Answer the following questions (written, ~paragraph each):\n",
    "  - What are the best predictors of genre?\n",
    "  - What information isn't very useful for predicting genre?\n",
    "  - What surprised you the most about your results?\n",
    "\n",
    "*Important caveats*:\n",
    "- This is going to be difficult data to work with - don't let the perfect be the enemy of the good!\n",
    "- Be creative in cleaning it up - if the best way you know how to do it is download it locally and edit as a spreadsheet, that's OK!\n",
    "- If the data size becomes problematic, consider sampling/subsetting\n",
    "- You do not need perfect or complete results - just something plausible that runs, and that supports the reasoning in your written answers\n",
    "\n",
    "If you find that fitting a model to classify *all* genres isn't very good, it's totally OK to limit to the most frequent genres, or perhaps trying to combine or cluster genres as a preprocessing step. Even then, there will be limits to how good a model can be with just this metadata - if you really want to train an effective genre classifier, you'll have to involve the other data (see stretch goals).\n",
    "\n",
    "This is real data - there is no \"one correct answer\", so you can take this in a variety of directions. Just make sure to support your findings, and feel free to share them as well! This is meant to be practice for dealing with other \"messy\" data, a common task in data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlI5OXfSag9C"
   },
   "source": [
    "## Resources and stretch goals\n",
    "\n",
    "- Check out the other .csv files from the FMA dataset, and see if you can join them or otherwise fit interesting models with them\n",
    "- [Logistic regression from scratch in numpy](https://blog.goodaudience.com/logistic-regression-from-scratch-in-numpy-5841c09e425f) - if you want to dig in a bit more to both the code and math (also takes a gradient descent approach, introducing the logistic loss function)\n",
    "- Create a visualization to show predictions of your model - ideally show a confidence interval based on error!\n",
    "- Check out and compare classification models from scikit-learn, such as [SVM](https://scikit-learn.org/stable/modules/svm.html#classification), [decision trees](https://scikit-learn.org/stable/modules/tree.html#classification), and [naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html). The underlying math will vary significantly, but the API (how you write the code) and interpretation will actually be fairly similar.\n",
    "- Sign up for [Kaggle](https://kaggle.com), and find a competition to try logistic regression with\n",
    "- (Not logistic regression related) If you enjoyed the assignment, you may want to read up on [music informatics](https://en.wikipedia.org/wiki/Music_informatics), which is how those audio features were actually calculated. The FMA includes the actual raw audio, so (while this is more of a longterm project than a stretch goal, and won't fit in Colab) if you'd like you can check those out and see what sort of deeper analysis you can do."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS1_231_Logistic_Regression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

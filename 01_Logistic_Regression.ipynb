{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "There are many options for regression. Recall that **linear regression** is helpful when predicting a real number along some continuum without a restricted range. Things like income and age.\n",
    "\n",
    "But what about . . .\n",
    "* probabilities\n",
    "* binary values (sick vs. healthy, male vs. female)\n",
    "* approval rating (0% to 100%)\n",
    "\n",
    "We need some \"squishification\" process to map numbers from a real number continuum to the unit interval (X range $-\\infty$ to $\\infty$, Y range 0 to 1). We need a **cumulative density function** - most commonly the **[sigmoid function](https://en.wikipedia.org/wiki/Sigmoid_function)**. This function in particular is useful because its calculous properties give it nice behaviors. (e^x derivative is e^x) Another common CDF is the **[probit function](https://en.wikipedia.org/wiki/Probit)** for probabilities.\n",
    "\n",
    "With logistic regression, we can even model general multinomial classification problems by combining several logistic regressions to predict membership in various classes and outputting the class that is most likely.\n",
    "\n",
    "At its heart, logistic regression is still linear. That is, the underlying math and optimization follow traditional linear regression. However, our coefficients won't have intuitive linear interpretation.\n",
    "\n",
    "$S(x) = \\frac{1}{1 + e^{-x}} = \\frac{e^x}{e^x + 1}$\n",
    "\n",
    "## Resources\n",
    "\n",
    "[5 Reasons ‚ÄúLogistic Regression‚Äù should be the first thing you learn when becoming a Data Scientist](https://towardsdatascience.com/5-reasons-logistic-regression-should-be-the-first-thing-you-learn-when-become-a-data-scientist-fcaae46605c4)\n",
    "\n",
    "\n",
    "**What data science methods are used at work?**\n",
    "[![](img/kaggle-common-algos.PNG)](https://www.kaggle.com/surveys/2017)\n",
    "\n",
    "Logistic regression is the baseline for classification models, as well as a handy way to predict probabilities (since those too live in the unit interval). While relatively simple, it is also the foundation for more sophisticated classification techniques such as neural networks (many of which can effectively be thought of as networks of logistic models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Linear vs. Logistic, Return of the Titanic üö¢\n",
    "\n",
    "To pull Titanic data from Kaggle:\n",
    "* create account\n",
    "* generate API Key and `kaggle.json`\n",
    "* join [Titanic competition](https://www.kaggle.com/c/titanic/data)\n",
    "\n",
    "The [Kaggle API](https://github.com/Kaggle/kaggle-api) enables lots of convenient methods for interacting with Kaggle.\n",
    "\n",
    "Here's how the data were sourced:\n",
    "```python\n",
    "!pip install kaggle\n",
    "\n",
    "import os, json\n",
    "\n",
    "path_to_config = \"../kaggle.json\"\n",
    "kaggle_config = json.loads(open(path_to_config).read())\n",
    "os.environ['KAGGLE_USERNAME'] = kaggle_config['username']\n",
    "os.environ['KAGGLE_KEY'] = kaggle_config['key']\n",
    "\n",
    "!kaggle competitions download -c titanic -p datasets/titanic\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "-PtztP8YlFym",
    "outputId": "8b18c64d-988a-44b1-e988-9de3fa61a5d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "1             2         1       1   \n",
       "3             4         1       1   \n",
       "6             7         0       1   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "\n",
       "    Parch    Ticket     Fare Cabin Embarked  \n",
       "1       0  PC 17599  71.2833   C85        C  \n",
       "3       0    113803  53.1000  C123        S  \n",
       "6       0     17463  51.8625   E46        S  \n",
       "10      1   PP 9549  16.7000    G6        S  \n",
       "11      0    113783  26.5500  C103        S  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How would we try to do this with linear regression?\n",
    "train_df = pd.read_csv('datasets/titanic/train.csv').dropna()\n",
    "test_df = pd.read_csv('datasets/titanic/train.csv').dropna()  # Unlabeled, for Kaggle submission\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QiZn2p1K8DED",
    "outputId": "be8b1a4c-ca08-4bba-98ed-3cda0942499c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.08389810726550939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.66567686, 0.68168731, 0.52351404, 0.74909452, 0.4779952 ,\n",
       "       0.58445856, 0.73115482, 0.91675714, 0.57710857, 0.43722395])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = ['Pclass', 'Age', 'Fare']\n",
    "target = 'Survived'\n",
    "\n",
    "X = train_df[predictors]\n",
    "y = train_df[target]\n",
    "\n",
    "linear_reg = LinearRegression().fit(X, y)\n",
    "print('score:', linear_reg.score(X, y))\n",
    "\n",
    "linear_reg.predict(test_df[predictors])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can you \"partially\" survive? You either survived or did not, like how our target column is encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fcxfpsjdFJwM",
    "outputId": "590a3bba-67fe-48b4-bf6e-91e67bd29bd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': -0.008293140798696792,\n",
       " 'Fare': 0.00048775407963190954,\n",
       " 'Pclass': -0.08596294986392504}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{attr: coef for attr, coef in zip(predictors, linear_reg.coef_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AFiisZU7_2Fr",
    "outputId": "97e9d9e2-6c2f-49b9-9955-e956b8d42e2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.14845883])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case = np.array([[1, 5, 500]])  # Rich 5-year old in first class\n",
    "linear_reg.predict(test_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can survial be greater than 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "dpUm8Dl-u2aB",
    "outputId": "44bc9b92-52ac-4e13-ab03-e87cbfd5fea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7103825136612022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression().fit(X, y)\n",
    "print(log_reg.score(X, y))\n",
    "\n",
    "log_reg.predict(test_df[predictors])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r7xWwqBrFuWL",
    "outputId": "4ea8705c-82b5-4378-cd8d-d0aca8e5d19e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict(test_case)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "flF3pcMHGGWw",
    "outputId": "4d5eef4c-e431-4486-b70f-dde06b7e3862"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02485552, 0.97514448])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict_proba(test_case)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9Bq-54noR1uE",
    "outputId": "b2650236-5573-4f84-d1a8-ce8bc6d1de17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': -0.02912512677284113,\n",
       " 'Fare': 0.004803700867242946,\n",
       " 'Pclass': -0.04550170440859573}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the math?\n",
    "{attr: coef for attr, coef in zip(predictors, log_reg.coef_[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Tj0mNL7_XWNV",
    "outputId": "effe14e5-839d-4ee0-e38d-fb80eef80ce4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.45878264])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AroeYscqR75f"
   },
   "outputs": [],
   "source": [
    "# The logistic sigmoid \"squishing\" function, implemented to accept numpy arrays\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e**(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "804BA7s0SggQ",
    "outputId": "61e0fcc7-adf9-4077-ba27-de875165cea1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97514448]])"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(log_reg.intercept_ + np.dot(log_reg.coef_, np.transpose(test_case)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, clearly a more appropriate model in this situation! For more on the math, [see this Wikipedia example](https://en.wikipedia.org/wiki/Logistic_regression#Probability_of_passing_an_exam_versus_hours_of_study).\n",
    "\n",
    "**Note:** while the sign (-/+) of coefficients provides information on the relationship between X and Y, we can't infer that a one-unit difference in X corresponds to a one-unit difference in Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Multinomial Logistic Regression\n",
    "\n",
    "[Absenteeism at work dataset](http://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work) has 21 classes. `sklearn.linear_model.LogisticRegression` automatically handles more than two classes by essentially treating each label as different (1) from some base class (0).\n",
    "\n",
    "Here's how the data were sourced:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = ('http://archive.ics.uci.edu/ml/'\n",
    "            'machine-learning-databases/00445/'\n",
    "            'Absenteeism_at_work_AAA.zip')\n",
    "\n",
    "extract_zip_url(data_url, 'datasets/abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation expense</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Son</th>\n",
       "      <th>Social drinker</th>\n",
       "      <th>Social smoker</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Absenteeism time in hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>168</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>172</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Reason for absence  Month of absence  Day of the week  Seasons  \\\n",
       "0  11                  26                 7                3        1   \n",
       "1  36                   0                 7                3        1   \n",
       "2   3                  23                 7                4        1   \n",
       "3   7                   7                 7                5        1   \n",
       "4  11                  23                 7                5        1   \n",
       "\n",
       "   Transportation expense  Distance from Residence to Work  Service time  Age  \\\n",
       "0                     289                               36            13   33   \n",
       "1                     118                               13            18   50   \n",
       "2                     179                               51            18   38   \n",
       "3                     279                                5            14   39   \n",
       "4                     289                               36            13   33   \n",
       "\n",
       "   Work load Average/day   Hit target  Disciplinary failure  Education  Son  \\\n",
       "0                 239.554          97                     0          1    2   \n",
       "1                 239.554          97                     1          1    1   \n",
       "2                 239.554          97                     0          1    0   \n",
       "3                 239.554          97                     0          1    2   \n",
       "4                 239.554          97                     0          1    2   \n",
       "\n",
       "   Social drinker  Social smoker  Pet  Weight  Height  Body mass index  \\\n",
       "0               1              0    1      90     172               30   \n",
       "1               1              0    0      98     178               31   \n",
       "2               1              0    0      89     170               31   \n",
       "3               1              1    0      68     168               24   \n",
       "4               1              0    1      90     172               30   \n",
       "\n",
       "   Absenteeism time in hours  \n",
       "0                          4  \n",
       "1                          0  \n",
       "2                          2  \n",
       "3                          4  \n",
       "4                          2  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/abs/Absenteeism_at_work.csv', sep=';')\n",
    "pd.options.display.max_columns = df.shape[1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinom_logistic(df, target, predictors, test_size=0.5, random_state=42):\n",
    "    X = df[predictors]\n",
    "    y = df[target]\n",
    "\n",
    "    if test_size:\n",
    "        X_train, X_test, Y_train, Y_test = (\n",
    "            train_test_split(X, y, test_size=test_size, \n",
    "                             random_state=random_state)\n",
    "        )\n",
    "    else:\n",
    "        X_train, X_test = [X] * 2\n",
    "        Y_train, Y_test = [y] * 2\n",
    "        \n",
    "    model = LogisticRegression(random_state=random_state, solver='lbfgs', \n",
    "                               multi_class='multinomial', max_iter=5000)\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    print('score:', model.score(X_test, Y_test))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5121621621621621\n"
     ]
    }
   ],
   "source": [
    "target = 'Reason for absence'\n",
    "predictors = sorted(list(set(df.columns) - \n",
    "                         set(['ID', 'Reason for absence'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.5121621621621621\n"
     ]
    }
   ],
   "source": [
    "# without train-test\n",
    "model = multinom_logistic(df, target, predictors, test_size=None, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.3810810810810811\n"
     ]
    }
   ],
   "source": [
    "model = multinom_logistic(df, target, predictors, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.3783783783783784\n"
     ]
    }
   ],
   "source": [
    "# smaller test size makes worse score\n",
    "model = multinom_logistic(df, target, predictors, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iblW74C8afuR"
   },
   "source": [
    "## Example 3: real-world classification\n",
    "\n",
    "We're going to check out a larger dataset - the [FMA Free Music Archive data](https://github.com/mdeff/fma). It has a selection of CSVs with metadata and calculated audio features that you can load and try to use to classify genre of tracks. To get you started:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean up the variable names in the dataframe\n",
    "- Use logistic regression to fit a model predicting (primary/top) genre\n",
    "- Inspect, iterate, and improve your model\n",
    "- Answer the following questions (written, ~paragraph each):\n",
    "  - What are the best predictors of genre?\n",
    "  - What information isn't very useful for predicting genre?\n",
    "  - What surprised you the most about your results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "SsySnuKaKtQf",
    "outputId": "d2855f29-b12c-4c1d-b86e-5867510e797a"
   },
   "outputs": [],
   "source": [
    "# # downloads 1.36 GB\n",
    "# data_url = 'https://os.unil.cloud.switch.ch/fma/fma_metadata.zip'\n",
    "# extract_zip_url(data_url, 'datasets/fma', flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "ut-Zfhp2LjcS",
    "outputId": "c29269ee-51e7-4ca2-c4d7-1e03c046a546",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\City_Year\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "tracks = (pd.read_csv('datasets/fma/tracks.csv', header=1)\n",
    "            .rename(columns={'Unnamed: 0':'track_id'})\n",
    "            .drop(0, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "id": "_qzn-IjIM1Pw",
    "outputId": "8b4fd4af-feff-49f0-d2ec-da238c58b716",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_released</th>\n",
       "      <th>engineer</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>information</th>\n",
       "      <th>listens</th>\n",
       "      <th>producer</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>tracks</th>\n",
       "      <th>type</th>\n",
       "      <th>active_year_begin</th>\n",
       "      <th>active_year_end</th>\n",
       "      <th>associated_labels</th>\n",
       "      <th>bio</th>\n",
       "      <th>comments.1</th>\n",
       "      <th>date_created.1</th>\n",
       "      <th>favorites.1</th>\n",
       "      <th>id.1</th>\n",
       "      <th>latitude</th>\n",
       "      <th>location</th>\n",
       "      <th>longitude</th>\n",
       "      <th>members</th>\n",
       "      <th>name</th>\n",
       "      <th>related_projects</th>\n",
       "      <th>tags.1</th>\n",
       "      <th>website</th>\n",
       "      <th>wikipedia_page</th>\n",
       "      <th>split</th>\n",
       "      <th>subset</th>\n",
       "      <th>bit_rate</th>\n",
       "      <th>comments.2</th>\n",
       "      <th>composer</th>\n",
       "      <th>date_created.2</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>duration</th>\n",
       "      <th>favorites.2</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres_all</th>\n",
       "      <th>information.1</th>\n",
       "      <th>interest</th>\n",
       "      <th>language_code</th>\n",
       "      <th>license</th>\n",
       "      <th>listens.1</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>number</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags.2</th>\n",
       "      <th>title.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:12</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>168.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4656.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1293.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>medium</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:14</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>237.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>514.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Electric Ave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:20</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>206.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>This World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:45:08</td>\n",
       "      <td>2008-02-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47632.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Constant Hitmaker</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Album</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexican Summer, Richie Records, Woodsist, Skul...</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-family:Verdana, Geneva, A...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2008-11-26 01:42:55</td>\n",
       "      <td>74.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kurt Vile, the Violators</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['philly', 'kurt vile']</td>\n",
       "      <td>http://kurtvile.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>192000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>2008-11-25 17:49:06</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>161.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>Pop</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54881.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>50135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Freeway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:45:05</td>\n",
       "      <td>2009-01-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;p&gt;¬†\"spiritual songs\" from Nicky Cook&lt;/p&gt;</td>\n",
       "      <td>2710.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Niris</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Album</td>\n",
       "      <td>1990-01-01 00:00:00</td>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Songs written by: Nicky Cook&lt;/p&gt;\\n&lt;p&gt;VOCALS...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008-11-26 01:42:52</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.895927</td>\n",
       "      <td>Colchester England</td>\n",
       "      <td>0.891874</td>\n",
       "      <td>Nicky Cook\\n</td>\n",
       "      <td>Nicky Cook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['instrumentals', 'experimental pop', 'post pu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:56</td>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>311.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[76, 103]</td>\n",
       "      <td>[17, 10, 76, 103]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>978.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>361.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Spiritual Level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  track_id  comments         date_created        date_released engineer  \\\n",
       "1        2       0.0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "2        3       0.0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "3        5       0.0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
       "4       10       0.0  2008-11-26 01:45:08  2008-02-06 00:00:00      NaN   \n",
       "5       20       0.0  2008-11-26 01:45:05  2009-01-06 00:00:00      NaN   \n",
       "\n",
       "   favorites   id                                information  listens  \\\n",
       "1        4.0  1.0                                    <p></p>   6073.0   \n",
       "2        4.0  1.0                                    <p></p>   6073.0   \n",
       "3        4.0  1.0                                    <p></p>   6073.0   \n",
       "4        4.0  6.0                                        NaN  47632.0   \n",
       "5        2.0  4.0  <p>¬†\"spiritual songs\" from Nicky Cook</p>   2710.0   \n",
       "\n",
       "  producer tags                 title  tracks   type    active_year_begin  \\\n",
       "1      NaN   []  AWOL - A Way Of Life     7.0  Album  2006-01-01 00:00:00   \n",
       "2      NaN   []  AWOL - A Way Of Life     7.0  Album  2006-01-01 00:00:00   \n",
       "3      NaN   []  AWOL - A Way Of Life     7.0  Album  2006-01-01 00:00:00   \n",
       "4      NaN   []     Constant Hitmaker     2.0  Album                  NaN   \n",
       "5      NaN   []                 Niris    13.0  Album  1990-01-01 00:00:00   \n",
       "\n",
       "       active_year_end                                  associated_labels  \\\n",
       "1                  NaN                                                NaN   \n",
       "2                  NaN                                                NaN   \n",
       "3                  NaN                                                NaN   \n",
       "4                  NaN  Mexican Summer, Richie Records, Woodsist, Skul...   \n",
       "5  2011-01-01 00:00:00                                                NaN   \n",
       "\n",
       "                                                 bio  comments.1  \\\n",
       "1  <p>A Way Of Life, A Collective of Hip-Hop from...         0.0   \n",
       "2  <p>A Way Of Life, A Collective of Hip-Hop from...         0.0   \n",
       "3  <p>A Way Of Life, A Collective of Hip-Hop from...         0.0   \n",
       "4  <p><span style=\"font-family:Verdana, Geneva, A...         3.0   \n",
       "5  <p>Songs written by: Nicky Cook</p>\\n<p>VOCALS...         2.0   \n",
       "\n",
       "        date_created.1  favorites.1  id.1   latitude            location  \\\n",
       "1  2008-11-26 01:42:32          9.0   1.0  40.058324          New Jersey   \n",
       "2  2008-11-26 01:42:32          9.0   1.0  40.058324          New Jersey   \n",
       "3  2008-11-26 01:42:32          9.0   1.0  40.058324          New Jersey   \n",
       "4  2008-11-26 01:42:55         74.0   6.0        NaN                 NaN   \n",
       "5  2008-11-26 01:42:52         10.0   4.0  51.895927  Colchester England   \n",
       "\n",
       "   longitude                                            members        name  \\\n",
       "1 -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "2 -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "3 -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...        AWOL   \n",
       "4        NaN                           Kurt Vile, the Violators   Kurt Vile   \n",
       "5   0.891874                                       Nicky Cook\\n  Nicky Cook   \n",
       "\n",
       "                                    related_projects  \\\n",
       "1  The list of past projects is 2 long but every1...   \n",
       "2  The list of past projects is 2 long but every1...   \n",
       "3  The list of past projects is 2 long but every1...   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "\n",
       "                                              tags.1  \\\n",
       "1                                           ['awol']   \n",
       "2                                           ['awol']   \n",
       "3                                           ['awol']   \n",
       "4                            ['philly', 'kurt vile']   \n",
       "5  ['instrumentals', 'experimental pop', 'post pu...   \n",
       "\n",
       "                                   website wikipedia_page     split  subset  \\\n",
       "1  http://www.AzillionRecords.blogspot.com            NaN  training   small   \n",
       "2  http://www.AzillionRecords.blogspot.com            NaN  training  medium   \n",
       "3  http://www.AzillionRecords.blogspot.com            NaN  training   small   \n",
       "4                      http://kurtvile.com            NaN  training   small   \n",
       "5                                      NaN            NaN  training   large   \n",
       "\n",
       "   bit_rate  comments.2   composer       date_created.2        date_recorded  \\\n",
       "1  256000.0         0.0        NaN  2008-11-26 01:48:12  2008-11-26 00:00:00   \n",
       "2  256000.0         0.0        NaN  2008-11-26 01:48:14  2008-11-26 00:00:00   \n",
       "3  256000.0         0.0        NaN  2008-11-26 01:48:20  2008-11-26 00:00:00   \n",
       "4  192000.0         0.0  Kurt Vile  2008-11-25 17:49:06  2008-11-26 00:00:00   \n",
       "5  256000.0         0.0        NaN  2008-11-26 01:48:56  2008-01-01 00:00:00   \n",
       "\n",
       "   duration  favorites.2 genre_top     genres         genres_all  \\\n",
       "1     168.0          2.0   Hip-Hop       [21]               [21]   \n",
       "2     237.0          1.0   Hip-Hop       [21]               [21]   \n",
       "3     206.0          6.0   Hip-Hop       [21]               [21]   \n",
       "4     161.0        178.0       Pop       [10]               [10]   \n",
       "5     311.0          0.0       NaN  [76, 103]  [17, 10, 76, 103]   \n",
       "\n",
       "  information.1  interest language_code  \\\n",
       "1           NaN    4656.0            en   \n",
       "2           NaN    1470.0            en   \n",
       "3           NaN    1933.0            en   \n",
       "4           NaN   54881.0            en   \n",
       "5           NaN     978.0            en   \n",
       "\n",
       "                                             license  listens.1 lyricist  \\\n",
       "1  Attribution-NonCommercial-ShareAlike 3.0 Inter...     1293.0      NaN   \n",
       "2  Attribution-NonCommercial-ShareAlike 3.0 Inter...      514.0      NaN   \n",
       "3  Attribution-NonCommercial-ShareAlike 3.0 Inter...     1151.0      NaN   \n",
       "4  Attribution-NonCommercial-NoDerivatives (aka M...    50135.0      NaN   \n",
       "5  Attribution-NonCommercial-NoDerivatives (aka M...      361.0      NaN   \n",
       "\n",
       "   number publisher tags.2          title.1  \n",
       "1     3.0       NaN     []             Food  \n",
       "2     4.0       NaN     []     Electric Ave  \n",
       "3     6.0       NaN     []       This World  \n",
       "4     1.0       NaN     []          Freeway  \n",
       "5     3.0       NaN     []  Spiritual Level  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5DvMPiM8MZeY",
    "outputId": "b80a4826-3f67-4e2b-8c98-808f55e63682"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106574, 53)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "track_id                  0\n",
       "comments                  0\n",
       "date_created           3529\n",
       "date_released         36280\n",
       "engineer              91279\n",
       "favorites                 0\n",
       "id                        0\n",
       "information           23425\n",
       "listens                   0\n",
       "producer              88514\n",
       "tags                      0\n",
       "title                  1025\n",
       "tracks                    0\n",
       "type                   6508\n",
       "active_year_begin     83863\n",
       "active_year_end      101199\n",
       "associated_labels     92303\n",
       "bio                   35418\n",
       "comments.1                0\n",
       "date_created.1          856\n",
       "favorites.1               0\n",
       "id.1                      0\n",
       "latitude              62030\n",
       "location              36364\n",
       "longitude             62030\n",
       "members               59725\n",
       "name                      0\n",
       "related_projects      93422\n",
       "tags.1                    0\n",
       "website               27318\n",
       "wikipedia_page       100993\n",
       "split                     0\n",
       "subset                    0\n",
       "bit_rate                  0\n",
       "comments.2                0\n",
       "composer             102904\n",
       "date_created.2            0\n",
       "date_recorded        100415\n",
       "duration                  0\n",
       "favorites.2               0\n",
       "genre_top             56976\n",
       "genres                    0\n",
       "genres_all                0\n",
       "information.1        104225\n",
       "interest                  0\n",
       "language_code         91550\n",
       "license                  87\n",
       "listens.1                 0\n",
       "lyricist             106263\n",
       "number                    0\n",
       "publisher            105311\n",
       "tags.2                    0\n",
       "title.1                   1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'genre_top'\n",
    "predictors = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kQUVlUKQMPPW"
   },
   "source": [
    "This is the biggest data you've played with so far, and while it does generally fit in Colab, it can take awhile to run. That's part of the challenge!\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "\n",
    "*Important caveats*:\n",
    "- This is going to be difficult data to work with - don't let the perfect be the enemy of the good!\n",
    "- Be creative in cleaning it up - if the best way you know how to do it is download it locally and edit as a spreadsheet, that's OK!\n",
    "- If the data size becomes problematic, consider sampling/subsetting\n",
    "- You do not need perfect or complete results - just something plausible that runs, and that supports the reasoning in your written answers\n",
    "\n",
    "If you find that fitting a model to classify *all* genres isn't very good, it's totally OK to limit to the most frequent genres, or perhaps trying to combine or cluster genres as a preprocessing step. Even then, there will be limits to how good a model can be with just this metadata - if you really want to train an effective genre classifier, you'll have to involve the other data (see stretch goals).\n",
    "\n",
    "This is real data - there is no \"one correct answer\", so you can take this in a variety of directions. Just make sure to support your findings, and feel free to share them as well! This is meant to be practice for dealing with other \"messy\" data, a common task in data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlI5OXfSag9C"
   },
   "source": [
    "## Resources and stretch goals\n",
    "\n",
    "- Check out the other .csv files from the FMA dataset, and see if you can join them or otherwise fit interesting models with them\n",
    "- [Logistic regression from scratch in numpy](https://blog.goodaudience.com/logistic-regression-from-scratch-in-numpy-5841c09e425f) - if you want to dig in a bit more to both the code and math (also takes a gradient descent approach, introducing the logistic loss function)\n",
    "- Create a visualization to show predictions of your model - ideally show a confidence interval based on error!\n",
    "- Check out and compare classification models from scikit-learn, such as [SVM](https://scikit-learn.org/stable/modules/svm.html#classification), [decision trees](https://scikit-learn.org/stable/modules/tree.html#classification), and [naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html). The underlying math will vary significantly, but the API (how you write the code) and interpretation will actually be fairly similar.\n",
    "- Sign up for [Kaggle](https://kaggle.com), and find a competition to try logistic regression with\n",
    "- (Not logistic regression related) If you enjoyed the assignment, you may want to read up on [music informatics](https://en.wikipedia.org/wiki/Music_informatics), which is how those audio features were actually calculated. The FMA includes the actual raw audio, so (while this is more of a longterm project than a stretch goal, and won't fit in Colab) if you'd like you can check those out and see what sort of deeper analysis you can do."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ayDccRP01GJD"
   },
   "source": [
    "# Data Science Unit 2 Sprint Challenge 3\n",
    "\n",
    "## Logistic Regression and Beyond\n",
    "\n",
    "In this sprint challenge you will fit a logistic regression modeling the probability of an adult having an income above 50K. The dataset is available at UCI:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/adult\n",
    "\n",
    "Your goal is to:\n",
    "\n",
    "1. Load, validate, and clean/prepare the data.\n",
    "2. Fit a logistic regression model\n",
    "3. Answer questions based on the results (as well as a few extra questions about the other modules)\n",
    "\n",
    "Don't let the perfect be the enemy of the good! Manage your time, and make sure to get to all parts. If you get stuck wrestling with the data, simplify it (if necessary, drop features or rows) so you're able to move on. If you have time at the end, you can go back and try to fix/improve.\n",
    "\n",
    "### Hints\n",
    "\n",
    "It has a variety of features - some are continuous, but many are categorical. You may find [pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) (a method to one-hot encode) helpful!\n",
    "\n",
    "The features have dramatically different ranges. You may find [sklearn.preprocessing.minmax_scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.minmax_scale.html#sklearn.preprocessing.minmax_scale) helpful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U22R1Ud51hxb"
   },
   "source": [
    "## Part 1 - Load, validate, and prepare data\n",
    "\n",
    "The data is available at: https://archive.ics.uci.edu/ml/datasets/adult\n",
    "\n",
    "Load it, name the columns, and make sure that you've loaded the data successfully. Note that missing values for categorical variables can essentially be considered another category (\"unknown\"), and may not need to be dropped.\n",
    "\n",
    "You should also prepare the data for logistic regression - one-hot encode categorical features as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SeOByIkht-NS"
   },
   "outputs": [],
   "source": [
    "# TODO - your work!\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",header=None,\\\n",
    "                 names =[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education_num\",\"marital_status\",\"occupation\"\\\n",
    "                         ,\"relationship\",\"race\",\"sex\",\"capital_gain\",\"capital_loss\",\"hours-per-week\"\\\n",
    "                         ,\"native_country\",\"Income\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours-per-week  native_country  Income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education_num     0\n",
       "marital_status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital_gain      0\n",
       "capital_loss      0\n",
       "hours-per-week    0\n",
       "native_country    0\n",
       "Income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov',\n",
       "       ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay',\n",
       "       ' Never-worked'], dtype=object)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"workclass\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"native_country\"] = df[\"native_country\"].replace(\" ?\", \"unknown_country_of_origin\")\n",
    "df[\"workclass\"] = df[\"workclass\"].replace(\" ?\", \"unknown_workclass\")\n",
    "df[\"occupation\"] = df[\"occupation\"].replace(\" ?\", \"unknown_occupation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sex\"] = df[\"sex\"]\n",
    "df[\"sex\"] = df[\"sex\"].replace(\" Male\",1)\n",
    "df[\"sex\"] = df[\"sex\"].replace(\" Female\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' White', ' Black', ' Asian-Pac-Islander', ' Amer-Indian-Eskimo',\n",
       "       ' Other'], dtype=object)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Income\"][0]\n",
    "df[\"Income\"] = df[\"Income\"].replace(\" <=50K\",0)\n",
    "df[\"Income\"] = df[\"Income\"].replace(\" >50K\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation = pd.DataFrame()\n",
    "unique_occupation = df[\"occupation\"].unique()\n",
    "for i in unique_occupation:\n",
    "    occupation[i] = df[\"occupation\"].apply(lambda x : 1 if i == x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "native_country = pd.DataFrame()\n",
    "unique_countries = df[\"native_country\"].unique()\n",
    "for i in unique_countries:\n",
    "    native_country[i] = df[\"native_country\"].apply(lambda x : 1 if i == x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "workclass = pd.DataFrame()\n",
    "unique_workclass = df[\"workclass\"].unique()\n",
    "for i in unique_workclass:\n",
    "    workclass[i] = df[\"workclass\"].apply(lambda x : 1 if i == x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_status = pd.DataFrame()\n",
    "unique_status = df[\"marital_status\"].unique()\n",
    "for i in unique_status:\n",
    "    marital_status[i] = df[\"marital_status\"].apply(lambda x : 1 if i == x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = pd.DataFrame()\n",
    "unique_race = df[\"race\"].unique()\n",
    "for i in unique_race:\n",
    "    race[i] = df[\"race\"].apply(lambda x : 1 if i ==x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Adm-clerical', ' Exec-managerial', ' Handlers-cleaners',\n",
       "       ' Prof-specialty', ' Other-service', ' Sales', ' Craft-repair',\n",
       "       ' Transport-moving', ' Farming-fishing', ' Machine-op-inspct',\n",
       "       ' Tech-support', 'unknown_occupation', ' Protective-serv',\n",
       "       ' Armed-Forces', ' Priv-house-serv'], dtype=object)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_numeric = df[[\"age\",\"education_num\",\"capital_gain\",\"capital_loss\", \"hours-per-week\"]]\n",
    "scaled_numeric = StandardScaler().fit_transform(scaled_numeric)\n",
    "scaled_numeric = pd.DataFrame(scaled_numeric)\n",
    "scaled_numeric.columns = [\"age\",\"education_num\",\"capital_gain\",\"capital_loss\", \"hours-per-week\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df.drop([\"native_country\",\"workclass\",\"marital_status\",\"race\",\"sex\", \"age\",\"education_num\",\\\n",
    "                          \"capital_gain\",\"capital_loss\", \"hours-per-week\",\"occupation\"],axis=1),\\\n",
    "                 native_country,workclass,marital_status,race, scaled_numeric,occupation],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RT1LFnFO1lo6"
   },
   "source": [
    "## Part 2 - Fit and present a Logistic Regression\n",
    "\n",
    "Your data should now be in a state to fit a logistic regression. Use scikit-learn, define your `X` (independent variable) and `y`, and fit a model.\n",
    "\n",
    "Then, present results - display coefficients in as interpretible a way as you can (hint - scaling the numeric features will help, as it will at least make coefficients more comparable to each other). If you find it helpful for interpretation, you can also generate predictions for cases (like our 5 year old rich kid on the Titanic) or make visualizations - but the goal is your exploration to be able to answer the question, not any particular plot (i.e. don't worry about polishing it).\n",
    "\n",
    "It is *optional* to use `train_test_split` or validate your model more generally - that is not the core focus for this week. So, it is suggested you focus on fitting a model first, and if you have time at the end you can do further validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7fTRDXguD7N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8457191991155878\n",
      "(-1.4450298468522036, ' Priv-house-serv')\n",
      "(-1.2809294575872798, ' Never-married')\n",
      "(-1.1523207211839943, ' Farming-fishing')\n",
      "(-1.0780808507669937, ' Dominican-Republic')\n",
      "(-1.0755863131506627, ' Vietnam')\n",
      "(-0.9927825175195835, ' Widowed')\n",
      "(-0.9472720604784176, ' Columbia')\n",
      "(-0.9289846009759934, ' Separated')\n",
      "(-0.8531125834368354, ' Divorced')\n",
      "(-0.8281875308881574, ' Without-pay')\n",
      "(-0.7837440760578854, ' Guatemala')\n",
      "(-0.7771940486169373, ' Other-service')\n",
      "(-0.7349510906745685, ' Amer-Indian-Eskimo')\n",
      "(-0.6293077125025529, ' Handlers-cleaners')\n",
      "(-0.619732424597482, ' Other')\n",
      "(-0.6063911533208567, ' Married-spouse-absent')\n",
      "(-0.5303421638171203, ' Greece')\n",
      "(-0.5083516124557407, ' Self-emp-not-inc')\n",
      "(-0.5047983634919838, ' South')\n",
      "(-0.4953940055911802, ' Outlying-US(Guam-USVI-etc)')\n",
      "(-0.4699560003045341, ' Trinadad&Tobago')\n",
      "(-0.4694865796793908, ' Thailand')\n",
      "(-0.45728221850031026, ' Nicaragua')\n",
      "(-0.4270836522610185, ' State-gov')\n",
      "(-0.38668786818777845, ' China')\n",
      "(-0.3739576371793224, ' Hungary')\n",
      "(-0.34741260216635933, ' Armed-Forces')\n",
      "(-0.3344406705584532, 'unknown_occupation')\n",
      "(-0.3252049622355393, ' Black')\n",
      "(-0.3122952728374045, 'unknown_workclass')\n",
      "(-0.2886044780172773, ' Machine-op-inspct')\n",
      "(-0.2616830055159165, ' Local-gov')\n",
      "(-0.23896033474790124, ' India')\n",
      "(-0.20160553799073258, ' El-Salvador')\n",
      "(-0.19193805736007244, ' Peru')\n",
      "(-0.1756177389024378, ' White')\n",
      "(-0.16525226982357602, ' Transport-moving')\n",
      "(-0.1390144102729937, ' Asian-Pac-Islander')\n",
      "(-0.13392325756956105, ' Private')\n",
      "(-0.0903835218655577, ' Honduras')\n",
      "(-0.08857428843724552, ' Ireland')\n",
      "(-0.040783995396782416, ' Holand-Netherlands')\n",
      "(-0.03485396259521786, ' Mexico')\n",
      "(-0.022145397721037442, ' Never-worked')\n",
      "(-0.01477507975491367, ' Scotland')\n",
      "(-0.0020048973312316453, ' Iran')\n",
      "(0.043926752016592914, ' Adm-clerical')\n",
      "(0.07138310369123824, ' Puerto-Rico')\n",
      "(0.07719930028710507, ' Self-emp-inc')\n",
      "(0.08000694442249837, 'unknown_country_of_origin')\n",
      "(0.08125737652956692, ' Laos')\n",
      "(0.09470496462372761, ' France')\n",
      "(0.14480315007962466, ' Jamaica')\n",
      "(0.14747189398156166, ' Ecuador')\n",
      "(0.1614769807226261, ' Poland')\n",
      "(0.1677344580269321, ' Craft-repair')\n",
      "(0.16939076830969269, ' England')\n",
      "(0.17846029791754542, ' Taiwan')\n",
      "(0.22146337204595418, ' Japan')\n",
      "(0.2749846052023052, 'capital_loss')\n",
      "(0.27695594497851245, ' Sales')\n",
      "(0.27843814913348314, ' Canada')\n",
      "(0.29854447945307144, ' Germany')\n",
      "(0.3515699791006948, ' United-States')\n",
      "(0.3579981779793518, ' Cuba')\n",
      "(0.3649436433387638, ' Portugal')\n",
      "(0.3758772795872665, 'age')\n",
      "(0.386295390477772, ' Philippines')\n",
      "(0.3939753028805726, 'hours-per-week')\n",
      "(0.3985282892565193, ' Hong')\n",
      "(0.42194980228648044, ' Federal-gov')\n",
      "(0.5198144425541599, ' Haiti')\n",
      "(0.5437971818543801, ' Yugoslavia')\n",
      "(0.5559767954382713, ' Protective-serv')\n",
      "(0.5926263244318797, ' Prof-specialty')\n",
      "(0.6379200616293667, ' Cambodia')\n",
      "(0.6534374760270851, ' Tech-support')\n",
      "(0.737820614375843, 'education_num')\n",
      "(0.8543839721241724, ' Exec-managerial')\n",
      "(0.9936785389019865, ' Italy')\n",
      "(1.2503457140956669, ' Married-AF-spouse')\n",
      "(1.417333972064514, ' Married-civ-spouse')\n",
      "(2.404160548309095, 'capital_gain')\n"
     ]
    }
   ],
   "source": [
    "# TODO - your work!\n",
    "X_train, X_test, y_train, y_test = train_test_split(df2.drop([\"Income\",\"relationship\", \\\n",
    "                                                              \"education\",\"fnlwgt\" ],axis=1), df2[\"Income\"] )\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "#predictions = np.array(log_reg.predict(X_test)).reshape(-1,1)\n",
    "y_test= np.array(y_test).reshape(-1,1)\n",
    "print(log_reg.score(X_test, y_test))\n",
    "b = np.array(X_train.columns)\n",
    "coef = (log_reg.coef_).flatten()\n",
    "z = zip(coef,b)\n",
    "z = sorted(z, key=lambda x: x[0])\n",
    "for i in z:\n",
    "    print(tuple(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropping capital_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8283994595258568\n",
      "(-1.4713189031452398, ' Priv-house-serv')\n",
      "(-1.2494792179911751, ' Never-married')\n",
      "(-1.109533637647043, ' Columbia')\n",
      "(-0.9325948667172679, ' Farming-fishing')\n",
      "(-0.8860953888975408, ' Separated')\n",
      "(-0.8655464885684683, ' Divorced')\n",
      "(-0.8288233467712248, ' Other-service')\n",
      "(-0.8265452341548828, ' Widowed')\n",
      "(-0.8193580758266263, ' Married-spouse-absent')\n",
      "(-0.7989109366255953, ' Without-pay')\n",
      "(-0.7485375785689419, ' Laos')\n",
      "(-0.7273139064364982, ' Dominican-Republic')\n",
      "(-0.6294730192838676, ' Other')\n",
      "(-0.5736245229142339, ' Amer-Indian-Eskimo')\n",
      "(-0.5735744305091174, ' Vietnam')\n",
      "(-0.5623478338122744, ' Outlying-US(Guam-USVI-etc)')\n",
      "(-0.5463771820790465, ' Handlers-cleaners')\n",
      "(-0.5307813596766675, ' Armed-Forces')\n",
      "(-0.5236428934961476, ' China')\n",
      "(-0.5160934643506764, ' Peru')\n",
      "(-0.48457460256319596, ' Self-emp-not-inc')\n",
      "(-0.48363806960390354, ' Thailand')\n",
      "(-0.477821926834758, ' South')\n",
      "(-0.4756542813201754, ' ?')\n",
      "(-0.4512042599430562, ' State-gov')\n",
      "(-0.4333068466013079, ' Greece')\n",
      "(-0.412874740581798, ' Hungary')\n",
      "(-0.4028261192520362, ' Mexico')\n",
      "(-0.39675753150568677, ' Machine-op-inspct')\n",
      "(-0.36370403418888836, ' Black')\n",
      "(-0.3293502787180306, 'unknown_workclass')\n",
      "(-0.3088778626209703, ' India')\n",
      "(-0.2887106137613838, ' Local-gov')\n",
      "(-0.2453613247227243, ' Nicaragua')\n",
      "(-0.2375976236995596, ' White')\n",
      "(-0.20402266125256527, ' Asian-Pac-Islander')\n",
      "(-0.19489257126073803, 'unknown_country_of_origin')\n",
      "(-0.14630400260212817, ' Never-worked')\n",
      "(-0.13925795290783147, ' Scotland')\n",
      "(-0.13423146666174976, ' Jamaica')\n",
      "(-0.09908642334590231, ' El-Salvador')\n",
      "(-0.09820186083042388, ' Honduras')\n",
      "(-0.05779615203543597, ' Private')\n",
      "(-0.028763547266504708, ' Transport-moving')\n",
      "(-0.01411806903757824, ' Holand-Netherlands')\n",
      "(0.008367423408584315, ' Puerto-Rico')\n",
      "(0.018644767157297744, ' Hong')\n",
      "(0.05397948994576448, ' Haiti')\n",
      "(0.054826654433774255, ' Adm-clerical')\n",
      "(0.058869011044531745, ' Ecuador')\n",
      "(0.08200748553091045, ' France')\n",
      "(0.10584924562905905, ' Taiwan')\n",
      "(0.10819642003956324, ' Iran')\n",
      "(0.11957920764251971, ' Guatemala')\n",
      "(0.12372078203123167, ' Craft-repair')\n",
      "(0.1359981538572276, ' Yugoslavia')\n",
      "(0.1440730187064481, ' Trinadad&Tobago')\n",
      "(0.1752059987903786, ' Self-emp-inc')\n",
      "(0.18331773917860106, ' Canada')\n",
      "(0.18575714026303888, ' Portugal')\n",
      "(0.18857401177662034, ' Japan')\n",
      "(0.29704544698789875, ' Sales')\n",
      "(0.310934504472073, ' United-States')\n",
      "(0.3213055832540422, ' Poland')\n",
      "(0.3732229861299797, ' Federal-gov')\n",
      "(0.3750678347734617, ' Cuba')\n",
      "(0.3795140419262778, 'hours-per-week')\n",
      "(0.4191332381141594, 'age')\n",
      "(0.4204485044205155, ' Philippines')\n",
      "(0.4544832280717092, ' Germany')\n",
      "(0.48008984641689856, ' Ireland')\n",
      "(0.5568098138894869, ' Protective-serv')\n",
      "(0.5640637194543644, ' England')\n",
      "(0.6011815623397946, ' Tech-support')\n",
      "(0.6840552006625472, ' Prof-specialty')\n",
      "(0.7607537957627534, 'education_num')\n",
      "(0.8850096968060854, ' Exec-managerial')\n",
      "(0.890004848247782, ' Cambodia')\n",
      "(0.9875059344555259, ' Italy')\n",
      "(1.3106316118740202, ' Married-AF-spouse')\n",
      "(1.3279709322366302, ' Married-civ-spouse')\n"
     ]
    }
   ],
   "source": [
    "# TODO - your work!\n",
    "X_train, X_test, y_train, y_test = train_test_split(df2.drop([\"Income\",\"relationship\", \\\n",
    "                                                              \"education\",\"fnlwgt\", \"capital_gain\", \"capital_loss\" ],axis=1), df2[\"Income\"] )\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "#predictions = np.array(log_reg.predict(X_test)).reshape(-1,1)\n",
    "y_test= np.array(y_test).reshape(-1,1)\n",
    "print(log_reg.score(X_test, y_test))\n",
    "b = np.array(X_train.columns)\n",
    "coef = (log_reg.coef_).flatten()\n",
    "z = zip(coef,b)\n",
    "z = sorted(z, key=lambda x: x[0])\n",
    "for i in z:\n",
    "    print(tuple(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BkIa-Sa21qdC"
   },
   "source": [
    "## Part 3 - Analysis, Interpretation, and Questions\n",
    "\n",
    "### Based on your above model, answer the following questions\n",
    "\n",
    "1. What are 3 features positively correlated with income above 50k?\n",
    "2. What are 3 features negatively correlated with income above 50k?\n",
    "3. Overall, how well does the model explain the data and what insights do you derive from it?\n",
    "\n",
    "*These answers count* - that is, make sure to spend some time on them, connecting to your analysis above. There is no single right answer, but as long as you support your reasoning with evidence you are on the right track.\n",
    "\n",
    "Note - scikit-learn logistic regression does *not* automatically perform a hypothesis test on coefficients. That is OK - if you scale the data they are more comparable in weight.\n",
    "\n",
    "### Match the following situation descriptions with the model most appropriate to addressing them\n",
    "\n",
    "In addition to logistic regression, a number of other approaches were covered this week. Pair them with the situations they are most appropriate for, and briefly explain why.\n",
    "\n",
    "Situations:\n",
    "1. You are given data on academic performance of primary school students, and asked to fit a model to help predict \"at-risk\" students who are likely to receive the bottom tier of grades.\n",
    "2. You are studying tech companies and their patterns in releasing new products, and would like to be able to model and predict when a new product is likely to be launched.\n",
    "3. You are working on modeling expected plant size and yield with a laboratory that is able to capture fantastically detailed physical data about plants, but only of a few dozen plants at a time.\n",
    "\n",
    "Approaches:\n",
    "1. Ridge Regression\n",
    "2. Quantile Regression\n",
    "3. Survival Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers\n",
    "1. What are 3 features positively correlated with income above 50k?\n",
    "    - hours per week\n",
    "    - being married to a government employee, AF or civil\n",
    "    - number of years of education\n",
    "\n",
    "2. What are 3 features negatively correlated with income above 50k?\n",
    "    - Working in the private service industry\n",
    "    - Never marrying or being widowed, or having an absent spouse\n",
    "    - Emmigrating from South American / Carribean countries\n",
    "3. Overall, how well does the model explain the data and what insights do you derive from it?\n",
    "    - This model has an accuracy of around 85%, indicating a pretty good model. I think this model would better predict a different income threshold. 50k is around median for America. I think there is probably a lot of noise around the average. Maybe adding a current city/zipcode or living in a city vs rural area would improve the model.\n",
    "    - I thought race would be a bigger factor, but it is a negative coefficient for black and white and Asian-Pac-Islander.\n",
    "    - even though capital_gain/loss seems like it would have too much predictive power, removing it does not change the accuracy of the model much. The Jamaican factor flipped from positive to negative\n",
    "    - I say all this, but maybe the model is more random than i thought. Cambodians have a large positive coefficient, but vietnamese people,laosians, and natives of thailand have a large negative coefficient. Maybe a feature for immigrant network effects would improve accuracy\n",
    "    - Local government employees coef is negative but government employees coef is positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I think Quantile Regression would be the best approach. Quant-reg would give us the best chance at not overestimating a student. We would understimate a lot of students, but we would be less likely to miss struggling students.\n",
    "2. I think survival analysis would be best for this situation. Suvival Analysis is used to model timelines and changes. By tracking the amount of time a company has taken to launch products, we could predict their ability to launch a product on time.\n",
    "3. Ridge Regression is best for this scenario. With a small sample size and a large number of features, we need a way to regularize(keep one feature from dominating the equation) our features and ridge regression is the best tool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yjj0sseiuHib"
   },
   "source": [
    "**TODO - your answers!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DS_Unit_2_Sprint_Challenge_3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
